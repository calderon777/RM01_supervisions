[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Research Methods for Land Economy",
    "section": "",
    "text": "Welcome\nWelcome to these interactive laboratory sessions for Research Methods in Land Economy. This digital workbook provides hands-on experience with R programming, quantitative analysis, and data visualisation techniques essential for contemporary research in land economy, finance, planning, and environmental housing studies.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Welcome and Supervision Overview</span>"
    ]
  },
  {
    "objectID": "index.html#supervisions-overview",
    "href": "index.html#supervisions-overview",
    "title": "Research Methods for Land Economy",
    "section": "Supervisions Overview",
    "text": "Supervisions Overview\nThese supervised laboratory sessions are designed for MPhil students beginning their quantitative research journey. Over several progressive supervision, you will develop from complete programming novice to confident data analysis skills, working with appropriate real-world land economy datasets from institutional sources and applying cutting-edge analytical techniques to substantive research questions in your field.\n\nAcademic Integration\nEach lab connects technical skill development with substantive research applications, ensuring that programming competency serves your broader academic and professional objectives. Youâ€™ll work with datasets relevant to housing policy, regional development, and planning analysis while developing reproducible research workflows used in leading academic institutions and policy organisations.\n\n\n\nHow to Use This Interactive Workbook\nThis workbook is designed as a practical, hands-on learning experience that requires active engagement with both the content and your RStudio environment. Success depends on following the structured approach outlined below.\n\n\nEssential Setup\n\nTechnical Requirements\nBefore beginning, ensure you have: - R (version â‰¥ 4.3) installed from r-project.org - RStudio Desktop (latest version) from posit.co - A stable internet connection for package installation and data downloads - Sufficient disk space (â‰¥ 2GB) for datasets and outputs\n\n\nğŸ’¾ Install R and RStudio on your laptops/gadgets\nRStudio is a wrapper for R; we are using RStudio because it makes looks R more organised and straightforward. Follow the following instructions:\n\ngo to https://www.r-project.org\nclick on â€˜CRAN mirrorâ€™\nchoose one of the two UK mirrors - https://www.stats.bris.ac.uk/R/ or https://cran.ma.imperial.ac.uk/\nClick on â€˜Download R for Windowsâ€™ or â€˜Download R for macOSâ€™\nClick on â€™install R for the first time\nClick on â€˜Download R-â€¦ for Windowsâ€™, the current version is R-4.5.1. Or alternatively, download the executable file for macOS.\ndouble-click the downloaded file, then click on â€˜Runâ€™, â€˜language:Englishâ€™, â€˜OKâ€™, and read and follow the instructions of installation until you click on â€˜Nextâ€™ for installing and â€˜Finishâ€™\n\nThen proceed to Installing RStudio.\n\nGo to rstudio.com\nclick on â€˜downloadâ€™\ndownload the Free version, download RStudio for Windows or macOS\nClick on â€˜Nextâ€™ if you agree and on â€˜Installâ€™ and â€˜Finishâ€™ to complete the process.\n\n\n\nProject Organisation\nCreate a dedicated folder structure for the course:\nRM01_Labs/\nâ”œâ”€â”€ data/           # Raw datasets and imports\nâ”œâ”€â”€ scripts/        # Your R code files  \nâ”œâ”€â”€ outputs/        # Generated plots, tables, reports\nâ”œâ”€â”€ certificates/   # Professional development documentation\nâ””â”€â”€ reflections/    # Written responses to critical questions\n\n\n\nActive Learning Protocol\n\n1. Read â†’ Code â†’ Reflect\nEach lab section follows this essential pattern: - Read the contextual material and instructions carefully - Code by replicating all examples in your RStudio session - Reflect by answering critical thinking questions in writing\n\n\n2. Hands-On Replication\nCritical: Do not simply read the code examples. You must: - Type (donâ€™t copy-paste) all code into RStudio scripts - Execute each code block and verify the outputs - Experiment with variations and modifications - Debug any errors before proceeding\n\n\n3. Documentation Standards\nMaintain professional documentation practices: - Save each lab as a separate R script (e.g., lab01_certification.R) - Comment your code extensively using # explanatory text - Include session information - Date and version your files systematically\n\n\n\nDeliverables\nEach lab includes specific deliverables: - Technical: Working R scripts with documented code - Visual: Publication-quality plots and analytical outputs\n- Written: Responses to all critical reflection questions - Professional: Certificates, portfolios, and documentation\n\n\nLearning Support\n\nGetting Help\nWhen you encounter difficulties: 1. Review the relevant section carefully for missed details or typos 2. Check R documentation using ?function_name or help(function_name) 3. Examine error messages systematicallyâ€”they often provide clear guidance and AI can often provide answers 4. Consult peers through appropriate academic channels 5. Attend supervision sessions prepared with specific questions\n\n\nCommon Pitfalls to Avoid\n\nPassive learning: You must complete the materials before attending the face-to-face supervisions.\nPassive reading: You must actively code to learn programming\nCopy-paste coding: Type examples yourself to build muscle memory\nIgnoring errors: Always resolve issues before proceeding\nSuperficial reflections: Engage deeply with methodological questions\nPoor organisation: Maintain systematic file and folder structures\n\n\n\nIndustry Applications\nR programming competency is increasingly valued in: - Policy Analysis: Government departments and think tanks - Consultancy: Urban planning, housing, and development firms - Research Organisations: Academic institutions and policy institutes - Data Science: Emerging opportunities across multiple sectors\n\n\n\n\nTechnical Notes\nLabs will introduce packages progressively. Install required packages as indicated in each session, and maintain a record of your technical environment using:\n# Document your session for reproducibility\nsessionInfo()\n\n\n\nGetting Started\nNavigate to Supervision 1 using the link to begin your journey into R programming for land economy research. Remember: this is an interactive learning experience that requires preparation before attending supervisions, your active participation, critical thinking, and professional engagement.\nSuccess in these labs depends not just on following instructions, but on developing the analytical thinking skills that will serve your research skills.\n\nFor technical support or academic guidance, consult your teaching team or attend designated office hours with specific questions prepared.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Welcome and Supervision Overview</span>"
    ]
  },
  {
    "objectID": "supervision_1.html",
    "href": "supervision_1.html",
    "title": "Supervision 1",
    "section": "",
    "text": "ğŸ§ª Lab 1 â€” R Quickstart",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Supervision 1</span>"
    ]
  },
  {
    "objectID": "supervision_1.html#lab-1-r-quickstart",
    "href": "supervision_1.html#lab-1-r-quickstart",
    "title": "Supervision 1",
    "section": "",
    "text": "ğŸ¯ Learning outcomes (you will be able to)\n\nOpen RStudio and recognise the Console, Script, Environment/History, Files/Plots/Help panes.\nCreate and run a short R script (comments, simple operations).\nSet your working directory to a course folder.\nCreate and inspect basic objects (a scalar and a small matrix).\nSave your script for the next supervision.\n\n\n\nğŸ§° Prerequisites\n\nRead â€œWelcome & Supervision Overviewâ€ section.\nR and RStudio installed.\nA course folder and subfolders on your machine where you will save scripts and other files:\n\nRM01_labs/\nâ”œâ”€â”€ data/           # For raw datasets and imports\nâ”œâ”€â”€ scripts/        # Your R code files  \nâ”œâ”€â”€ outputs/        # Generated plots, tables, reports\nâ”œâ”€â”€ certificates/   # Professional development documentation\nâ””â”€â”€ reflections/    # Written responses to critical questions\n\n\nğŸ“˜ Introduction to R\nAfter downloading and installing open RStudio, we will cover now some tutorials.\nğŸ‘¨â€ğŸ’» Long Tutorial\nWe would cover a brief introduction on this labs, students can use a longer tutorial for detailed learning at https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf\n\n\nA. Get oriented in RStudio\nYou need to have installed R and RStudio to continue with this lab.\n\nOpen Rstudio in your computer.\n\n\n\n\nOn this picture, there are three panels â€˜the Consoleâ€™, â€˜The Environmentâ€™, and â€˜The Plots, Help and Filesâ€™ panel.\n\n\n\nLetâ€™s choose a better appeareance for our RStudio. Click on Tools&gt;Global Options.\n\n\n\n\nIn RStudio, click on â€˜Toolsâ€™ and â€˜Global Optionsâ€™\n\n\n\nAfterwards, in the window â€œOptionsâ€, click on â€œAppearanceâ€, RStudio theme: â€œModernâ€, Editor font: â€œCourierâ€, Editor theme: Cobalt. Finally, click on â€œApplyâ€\n\n\n\n\nYou are here by clicking on Tools&gt;Global Options..&gt;Appereance&gt;Modern&gt;Courier&gt;Cobalt&gt;Apply\n\n\n\n\n\nB. Your first script\n\nOpen a file to save the code for this session. Click on File â†’ New File â†’ R Script; or simply press Ctrl+Shift+N (command+shift+enter in Mac); this will open a new panel called â€˜Scriptâ€™ where we are going to write the commands for R. Change the name of the script to â€œlab_1â€, saving the script in the folder RM01_Labs/scripts/ File â†’ Save As â†’ â€œlab_1â€\n\n\n\n\nClick on File&gt;New File&gt;R Script\n\n\n\nAdd a comment (starts with #.) On the script panel, type the caracter # and then write 'LAB ONE AND TODAY'S DATE'. R will ignore any line of command starting with #. You can use # to add comments, titles, reminders within your R code/ R Script.\n\nYour R Script now shall look similar to this:\n\n\n\nComments are crucial to learn R\n\n\nThe Rstudio screen has four windows or panels: 1. Console. 2. Environment and history. 3. Files, plots, packages and help. 4. The R script(s) and data view. The R script is where you keep a record of your work or commands - in a line by line basis.\n\nOn your script, type getwd() in line number â€˜2â€™ and hit the keys â€˜ctrl+enterâ€™ in your keyboard (The + indicates â€˜do it at the same timeâ€™), you dont need to press the key â€˜+â€™. After â€˜runningâ€™ line 2, you will see in the console panel the working directory (or folder) that R is using to download and upload files.\n\n\n\n\nThis image shows how your R Script should look\n\n\n\n\n\nThe outcome in the console -bottom panel after getwd()\n\n\n\n\n\nC. Set your working directory\nChoose your course file folder ğŸ“. Recall we called the working folder folder â€˜RM01_labsâ€™. In RStudioâ€™ go to â€˜Sessionâ€™, â€˜Set Working Directoryâ€™, â€˜Choose Directoryâ€™, and select this folder.\n\n\n\nCreate your folder and then click on Session&gt;Set Working Directory&gt;Choose Directory\n\n\nThe â€˜Consoleâ€™ panel renders setwd(and a path/directory to your chosen folder in your computer). Copy and paste this output in line 3 from your Console to your R Script. Setting the directory with code and not â€˜clicksâ€™ will save you time.\n\n\n\nThis is the code you shall copy and paste in your R Script, ignore â€˜&gt;â€™\n\n\n\n\n\nsetwd() in your R Script\n\n\nSo far, we have created the following script:\n# LAB ONE 25/09/2025\ngetwd()\nsetwd(\"C:/Users/YOUR DIRECTORY/RM01_labs\")\nand this is the Console output:\n&gt; # LAB ONE 25/09/2025\n&gt; getwd()\n[1] \"C:/Users/YOUR DIRECTORY/Documents\"\n&gt; setwd(\"C:/Users/YOUT DIRECTORY/RM01_labs\")\n\n\nD. First calculations & a matrix (3â€“4 min)\n\nIn your script, run: 5 * 5 (result should be 25 in the Console).\n\n\n&gt; 5*5\n[1] 25\n\n\nCreate a small matrix and run it. Use the following code, explanatory comments are written with #:\n# A is an object, \n# &lt;- is similar to equal\n# 1:8 are the numbers from 1 to 8\n# nrow is the matrix number of rows = 4\n# ncol is the matrix number of columns = 2 \nA &lt;- matrix(1:8, nrow = 4, ncol = 2)\n# The object A now has a matrix. Run the object A\nA\nThe outcome in the console shall be as follows:\n\n\n&gt; # A is an object, \n&gt;    # &lt;- is similar to equal\n&gt;    # 1:8 are the numbers from 1 to 8\n&gt;    # nrow is the matrix number of rows = 4\n&gt;    # ncol is the matrix number of columns = 2 \n&gt;    A &lt;- matrix(1:8, nrow = 4, ncol = 2)\n&gt;    # The object A now has a matrix. Run the object A\n&gt;    A\n     [,1] [,2]\n[1,]    1    5\n[2,]    2    6\n[3,]    3    7\n[4,]    4    8\n\n\nIn brief, you created a matrix called â€˜Aâ€™, with numbers from 1 to 8, with four rows and two columns.\n\n\n\n\nE. Inspect objects & view data\n\nCheck the Environment tab to see objects youâ€™ve created.\nThe tab History shows a list of commands used do far.\n\n\n\n\nEnvironment Panel\n\n\n\nTo see the matrix A in a new window, type the command View(A) in your script and hit the keys â€˜ctrl+enterâ€™ to run that line , this will send you to a different tab. Afterwards, click on your R script to come back.\n\n# LAB ONE 25/09/2025\ngetwd()\nsetwd(\"C:/Users/Cam/OneDrive - University of Cambridge/Cambridge 2025-26/RM01_labs\")\n5*5\n# A is an object, \n# &lt;- is similar to equal\n# 1:8 are the numbers from 1 to 8\n# nrow is the matrix number of rows = 4\n# ncol is the matrix number of columns = 2 \nA &lt;- matrix(1:8, nrow = 4, ncol = 2)\n# The object A now has a matrix. Run the object A\nA\nView(A)\n\n\nF. (Optional) Install and load a package\nThe tab â€˜Packagesâ€™ shows the list of add-ons included in the installation of RStudio. Click on the tab â€˜Packagesâ€™, if you check a box next to a package, that package is loaded into R, if not, any command related to that package wonâ€™t work, you will need select it. You can also install other add-ons by clicking on the â€˜Installâ€™ icon.\nAnother way to install add-ons is to type the function install.packages(\"name of the package\"), and then you will be able to open the library of commands of that package.\n\nIn line 8, to install the package forecast, type install.packages(â€œforecastâ€) and hit ctrl+enter. If a window opens, you can hit yes to restart RStudio. See the picture below, make sure you do not get errors in the console. The sign â€˜&gt;â€™ will show when R finishes running a line.\n\n# the function to install packages in R\n# we use \"forecast\" as example\ninstall.packages(\"forecast\") # to install the package\nlibrary(forecast) # to activate the package 'forecast'\nRemember to activate the package by typing â€˜library(the package)â€™, for example, library(forecast) and ctrl+enter. This will activate all functions within the â€˜forecastâ€™ package.\nMake sure there are no error messages in the installation, and if so, make sure to solve the issue before continuing.\nThe package forecast is used to analyse and predict time series (e.g.Â yearly house prices during the last 20 years).\nScript/Data View Window:\nâ€¢ Begin scripts with a comment for title and description using the hash character (#). Anything after the hash on the same line is considered a comment and is ignored by R. â€¢ Code can continue to the next line without a special character, but only if the previous line ends in a way that suggests continuation (e.g., a comma or unclosed brackets). â€¢ To run a line of code, position the cursor on the line and press Ctrl+Enter. For multiple lines, select them and press Ctrl+Enter.\nConsole/Output Window:\nâ€¢ Itâ€™s recommended to work in script mode for reusability. â€¢ Commands outside the script context can be typed at the bottom of the console, indicated by the â€œ&gt;â€ sign. â€¢ Press Enter to execute a command. â€¢ Use the up and down arrows to revisit and edit older lines of code previously typed into the console.\n\n\n\nğŸ’¾ Save your script\nFile â†’ Save (e.g., lab_1) into your â€˜scriptâ€™ folder. Remember to save your R Scripts after each supervision, this will save you a lot time!\n\n\nâœ… Checkâ€‘off\n\nI can run code from a script (Ctrl+Enter).\nMy working directory is set via setwd() at the top of the script.\nI created A &lt;- matrix(1:8, 4, 2) and can see it in Environment.\nScript saved.\n\n\nğŸ End of Lab 1 ğŸ›‘ Remember to save your script ğŸ’¾",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Supervision 1</span>"
    ]
  },
  {
    "objectID": "supervision_1.html#lab-2-professional-development-r-certification-via-linkedin-learning",
    "href": "supervision_1.html#lab-2-professional-development-r-certification-via-linkedin-learning",
    "title": "Supervision 1",
    "section": "ğŸ§ª Lab 2 â€” Professional Development: R Certification via LinkedIn Learning",
    "text": "ğŸ§ª Lab 2 â€” Professional Development: R Certification via LinkedIn Learning\nProfessional certifications complement academic learning by providing industry-recognised credentials. For land economy graduates leading industries and entering consultancy, government, or research roles, demonstrating quantitative competency through multiple channels strengthens your professional profile and evidences commitment to continuous learning.\n\n\nLearning outcomes\nBy the end of this lab you will be able to:\n\nAccess institutional resources / LinkedIn Learning for continuous professional development\nComplete a certified R programming course that demonstrates foundational competency\nDocument your learning through professional certification pathways\nPrepare your technical environment for advanced coursework\nReflect critically on skill acquisition in academic and professional contexts\n\n\n\n\nPrerequisites\n\nUniversity credentials for LinkedIn Learning access.\n\nR and RStudio installed (youâ€™ll run a small code check).\n\n\n\n\nğŸ§ª Part A â€” Firstâ€‘time access to LinkedIn Learning (20 minutes)\nEstablish access to University-provided LinkedIn Learning resources.\n\nFollow the UIS guidance: help.uis.cam.ac.uk/service/support/training/linkedin-learning-info (opens the official instructions).\n\n\n\nChoose Login with your University account (SSO). If prompted, connect to an existing LinkedIn profile (optional, but helpful for saving certificates).\n\n\n\n\nğŸ§ª Part B â€” Course Selection and Academic Alignment\n\nIn LinkedIn Learning, search for â€œR Programmingâ€ or â€œR for Data Analysisâ€.\n\nPick a Beginner course or a Learning Path that issues a certificate upon completion.\n\nSkim the syllabus; confirm it covers: R basics (e.g.Â objects, vectors), data frames, importing data, and simple plots.\n\n\nShort beginner certificates often take only a few hours. Pick one you can finish this week.\n\nğŸ’­ Reflect: a) Provide a certificate/enrolment URL or a screenshot proving enrolment. What challenges do you anticipate in acquiring programming skills alongside your substantive coursework? b) List three new R commands and three packages you learned and one common error you corrected.\n\n\n\nğŸ§ª Part C â€” Add to your LinkedIn profile (optional but recommended)\n\nOpen your LinkedIn profile â†’ Add profile section â†’ Recommended â†’ Licenses & Certifications.\n\nName: Course title. Issuing organization: LinkedIn Learning. Credential URL: paste the certificate share link (if available).\n\nSave.\n\n\n\n\nğŸ§ª Part D â€” RStudio techâ€‘check for upcoming labs\nRun the following lines in RStudio to ensure youâ€™re ready for the following Labs.\n\nRecall you can run lines of code in R by hitting the keys ctrl+enter (commad+enter for Mac)\n\n\nR.version.string\n\n[1] \"R version 4.4.2 (2024-10-31 ucrt)\"\n\nsessionInfo()$running\n\n[1] \"Windows 10 x64 (build 19045)\"\n\n\nInstall key packages (run once):\n\n# install all packages at once\ninstall.packages(c(\"learnr\", \"r4ds.tutorials\", \"readr\", \"readxl\", \"ggplot2\"))\n\nVerify they load and basic plotting works:\n\n# Create a small data frame with x = 1,...,10 and y = sqrt(x).\n# We'll use this to do a quick \"tech check\" with a base R plot.\ndf &lt;- data.frame(x = 1:10, y = (1:10)^0.5)\n\n# Base R line plot:\n# - type = \"l\" draws a line (instead of points).\n# - main/xlab/ylab set the title and axis labels.\n# This confirms base graphics are working and shows a concave curve of sqrt(x).\nplot(df$x, df$y, type = \"l\",\n     main = \"Tech check: base plot\",\n     xlab = \"x\",\n     ylab = \"sqrt(x)\")\n\n\n\n\n\n\n\n\n\n# -----------------------------------------------\n# Test basic plotting capability with ggplot2\n# -----------------------------------------------\n\n# Load ggplot2 (grammar of graphics) for layered, customizable plots.\nlibrary(ggplot2)\n\n# Create a toy dataset: yearly \"average house prices\" (hypothetical numbers).\n# This lets us test lines, points, labels, and themes in ggplot2.\ntest_data &lt;- data.frame(\n  year = 2010:2020,\n  house_prices = c(250000, 260000, 275000, 285000, 290000, \n                   310000, 325000, 340000, 355000, 370000, 385000)\n)\n\n# Start a ggplot:\n# - aes(x = year, y = house_prices) maps variables to axes.\n# - geom_line() draws the trend line; linewidth controls thickness.\n# - geom_point() adds markers at each year.\n# - scale_y_continuous(labels = scales::comma_format()) formats y-axis with commas (e.g., 310,000).\n# - labs() sets a clear title, subtitle, axis labels, and a caption.\n# - theme_minimal() gives a clean, publication-style look.\nggplot(test_data, aes(x = year, y = house_prices)) +\n  geom_line(colour = \"steelblue\", linewidth = 1.2) +   # trend line\n  geom_point(colour = \"darkred\", size = 2) +           # points on each year\n  scale_y_continuous(labels = scales::comma_format()) +# pretty y-axis labels\n  labs(\n    title = \"Hypothetical House Price Trends\",         # main title\n    subtitle = \"System functionality test\",            # context/subtitle\n    x = \"Year\",                                        # x-axis label\n    y = \"Average House Price (Â£)\",                     # y-axis label\n    caption = \"Test data for R/RStudio verification\"   # caption under the plot\n  ) +\n  theme_minimal()                                      # clean theme\n\n\n\n\n\n\n\n\nğŸ’­ Reflect: Did everything install and run without warnings? Capture any errors so we can fix them in class.\n\n\n\nBest practices\n\nPractice while you watchâ€”replicate examples in RStudio, donâ€™t just read the labs and watch videos.\n\nKeep a snippets file (your personal cheatâ€‘sheet) with commands youâ€™ll reuse.\n\nStore all artifacts (notes, PDFs) in your course project folder for quick reference.\n\n\nğŸ End of Lab 2 ğŸ›‘ Remember to save your script ğŸ’¾",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Supervision 1</span>"
    ]
  },
  {
    "objectID": "supervision_1.html#lab-3-interactive-r-learning-building-programming-competency",
    "href": "supervision_1.html#lab-3-interactive-r-learning-building-programming-competency",
    "title": "Supervision 1",
    "section": "ğŸ§ª Lab 3 â€” Interactive R Learning: Building Programming Competency",
    "text": "ğŸ§ª Lab 3 â€” Interactive R Learning: Building Programming Competency\n\n\nLearning outcomes\nThis lab exposes you to different pedagogical approaches in quantitative methods education while building the practical skills necessary for data-driven research in land economy.\nBy the end of this lab you will be able to:\n\nNavigate multiple R learning platforms with different pedagogical approaches\nComplete structured programming exercises with immediate feedback\nDevelop troubleshooting skills through guided problem-solving\nAcquire multiple ways of self-development for your own study plan.\n\n\n\n\nPrerequisites\n\nR (â‰¥ 4.1) and RStudio.\nPackages (install once):\n\n\ninstall.packages(c(\"learnr\", \"r4ds.tutorials\", \"swirl\"))\n\n\nIf tutorials donâ€™t appear in RStudioâ€™s Tutorial tab after installation, restart R.\n\n\n\n\nPart A â€” r4ds.tutorials: 01-data-visualization\nThis runs as an interactive tutorial in RStudioâ€™s Tutorial pane.\n\n# Option 1: via code\nlearnr::run_tutorial(\"01-data-visualization\", package = \"r4ds.tutorials\")\n\n# Option 2: discover tutorials installed on your system\nlearnr::available_tutorials(\"r4ds.tutorials\")\n\nDo this: 1. Start and complete the tutorial on data visualization. Use the Show in New Window icon if the pane is small. 2. When you reach the Submit page, follow its instructions and save the html (we wonâ€™t collect submissions in this lab, just finish to the end).\nğŸ’­ Reflect: - What topic would benefit from additional practice or explanation? e.g.Â aesthetics (e.g., aes(x, y, color)) and geoms (e.g., geom_point(), geom_line())\n\n\n\nPart B â€” learnr: ex-data-basics\nThis is a short core tutorial bundled with learnr.\n\n# open interactive tutorial in the package 'learnr'\nlearnr::run_tutorial(\"ex-data-basics\", package = \"learnr\")\n\n# Explore other tutorials\nlearnr::run_tutorial(, package = \"learnr\")\n\nDo this: Complete all exercises for the tutorial â€˜ex-data-basicsâ€™..\nğŸ’­ Reflect: - What is the difference between a tibble and a data frame? - Why might tibbles be preferred in modern R workflows?\n\n\n\nPart C â€” swirl (consoleâ€‘based)\nswirl runs entirely in the Console and saves your progress.\n\n# Install/run swirl\ninstall.packages(\"swirl\")\nlibrary(swirl)\n\n# Start swirl\nswirl()\n# (enter your name when prompted)\n\n# Install and start a course (first time only)\ninstall_from_swirl(\"R Programming\")   # or \"R_Programming\"\n\n# At any time, leave swirl with\n# bye()\n\n# Check progress later\nswirl::progress()\n\nDo this: - Install R Programming and complete the first lesson. - Exit with bye() and verify progress with swirl::progress().\nğŸ’­ Reflect: - How does working in the Console (swirl) feel compared with the GUI tutorials?\n\n\n\nPart D â€” Mini practice\nCreate a tiny vector and compute a statistic, then plot a quick line:\n\n# create variable x\nx &lt;- 1:10\n#calculate the mean and asign it to mean_x\nmean_x &lt;- mean(x)\n# review mean_x\nmean_x\n\n[1] 5.5\n\n# quick plotting function\nplot(x, type = \"l\", main = \"Quick line\", ylab = \"x\")\n# abline adds horizontal (h) or vertical (v) lines.\nabline(h = mean_x, lty = 2)\n\n\n\n\n\n\n\n\nğŸ’­ Reflect: - Which approach (r4ds.tutorials, learnr, swirl) best prepared you to learn R coding independently?\n\n\n\nBest practices\n\nUse learnr/r4ds.tutorials for guided practice with hints, autoâ€‘checks, and saved state.\nUse swirl when you prefer keyboardâ€‘only Console practice or have limited UI.\nRestart RStudio if tutorials donâ€™t show; list whatâ€™s available with learnr::available_tutorials().\nKeep your scripts open alongside tutorials to copy refined solutions into your own notes.\n\n\nğŸ End of Lab 3 ğŸ›‘ Remember to save your script ğŸ’¾",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Supervision 1</span>"
    ]
  },
  {
    "objectID": "supervision_1.html#lab-4-uploading-excel-csv-files-to-r-pipr",
    "href": "supervision_1.html#lab-4-uploading-excel-csv-files-to-r-pipr",
    "title": "Supervision 1",
    "section": "ğŸ§ª Lab 4 â€” Uploading Excel & CSV Files to R (PIPR)",
    "text": "ğŸ§ª Lab 4 â€” Uploading Excel & CSV Files to R (PIPR)\n\n\nLearning outcomes\nBy the end of this lab you will be able to: 1. Download the Private rents annual inflation to August 2024 monthly workbook and save it in a tidy project structure. 2. Import Excel (.xlsx/.xls) and CSV files using RStudioâ€™s Import Dataset UI and reproducible R code. 3. Deal with metadata/header rows via skip, set col_names, and verify column types. 4. Plot time series (index and annual % change) with base R and add reference lines. 5. Use help pages (e.g., ?plot) and annotate charts for a policy audience.\n\n\n\nPrerequisites\n\nR (â‰¥ 4.0) and RStudio.\nProject folder (e.g., RM01_labs/) with subfolder data/.\nPackages (install once):\n\n\n# Make sure to install the packages.\n# install.packages(c(\"readxl\", \"readr\"))\n\n\nğŸ’¡ Tip: Prefer file names without spaces and lower-cases, e.g.Â pipr_monthly.xls rather than pipr monthly.xls.\n\n\n\n\nPart A â€” Get PIPR monthly from ONS (manual steps)\n\nGo to ONS.gov.uk and search Private rents annual inflation, UK countries, January 2016 to August 2024. This lab is using ONS data on Figure 4: Rent annual inflation slowed across the UK, Private rents annual inflation, across the UK, January 2016 to August 2025.\n\n\n\n\nThis is the website / data source.\n\n\n\n\n\nThis is the the data we used in the tutorial.\n\n\n\nOn the dataset page, choose Data â†’ Download monthly workbook. Save the file as Excel and CSV Comma delimited.\nSave as data/pipr_monthly.xls inside your project folder (e.g., RM01_labs/) with subfolder data/.\n(Optional) Open the file and identify the sheet that contains the UK and country/regions.\n\nğŸ’­ Reflect: Why does PIPR (rents) provide a more direct lens on housing affordability and regional pressures than GDP for planning and regeneration?\n\n\n\nPart B â€” Import Excel via code (reproducible)\nUse readxl::read_excel() and inspect column names to choose the UK series.\n\nlibrary(readxl)\n# Adjust 'sheet' and 'skip' depending on the workbook structure you download.\n# we use skip = 7 because there are headings in the first 7 rows of the dataset.\npipr_raw &lt;- read_excel(\"data/pipr_monthly.xls\", sheet = 1, skip = 7)\n\n# Inspect names to locate the date/month, UK Index, and UK annual % change columns\nnames(pipr_raw)\n\n[1] \"Date\"             \"UK\"               \"England\"          \"Wales\"           \n[5] \"Scotland\"         \"Northern Ireland\"\n\n# A good practice is to keep a copy of the raw data and create a new version of the data for manipulation.\n\npipr&lt;-pipr_raw\n\n# rename column names for easiness. \nnames(pipr) &lt;- c(\"month\", \"uk\", \"england\", \"wales\", \"scotland\", \"n_ireland\")\n\nstr(pipr)\n\ntibble [116 Ã— 6] (S3: tbl_df/tbl/data.frame)\n $ month    : POSIXct[1:116], format: \"2016-01-01\" \"2016-02-01\" ...\n $ uk       : num [1:116] 3.3 3.3 3.4 3.3 3.2 3.3 3.4 3.3 3.2 3.3 ...\n $ england  : num [1:116] 3.5 3.5 3.6 3.5 3.3 3.5 3.7 3.6 3.5 3.6 ...\n $ wales    : num [1:116] 1.2 0.8 0.8 0.6 0.4 0.3 0.3 0.9 1.4 1.3 ...\n $ scotland : num [1:116] 2.1 1.8 1.6 1.5 1.4 1.1 1.2 0.9 1.1 1.1 ...\n $ n_ireland: num [1:116] 1.1 1.3 1.4 1.6 1.6 1.6 1.5 1.5 1 0.9 ...\n\nhead(pipr, 6)\n\n# A tibble: 6 Ã— 6\n  month                  uk england wales scotland n_ireland\n  &lt;dttm&gt;              &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 2016-01-01 00:00:00   3.3     3.5   1.2      2.1       1.1\n2 2016-02-01 00:00:00   3.3     3.5   0.8      1.8       1.3\n3 2016-03-01 00:00:00   3.4     3.6   0.8      1.6       1.4\n4 2016-04-01 00:00:00   3.3     3.5   0.6      1.5       1.6\n5 2016-05-01 00:00:00   3.2     3.3   0.4      1.4       1.6\n6 2016-06-01 00:00:00   3.3     3.5   0.3      1.1       1.6\n\n\n\n\n\nPart C â€” Import via RStudio UI (reference)\n\nGo to RStudio â†’ Import Dataset â†’ From Excel â†’ select data/pipr_monthly.xls.\n\n\n\n\nimporting from Rstudio with â€˜import datasetâ€™\n\n\n\nChoose the relevant sheet and, if needed, set Skip for metadata rows (recall we used skip = 7 in Part B).\n\n\n\n\nImport Ecvel data window\n\n\n\nSet Name to pipr_monthly and verify column names (e.g., month, uk_index, uk_yoy).\nClick Copy to grab the generated R code, then Import.\n\nPaste the generated code in your R script so your workflow is reproducible.\n\n\n\nPart D â€” Basic timeâ€‘series line plot (annual % change)\nThe following code plots PIPR annual % change for the UK as a line. Label the xâ€‘axis sparsely to keep it readable.\n\n# Create a line plot of UK private rent annual % changes\nplot(pipr$uk, type = \"l\",  # type = \"l\" means line plot\n     xlab = \"\",  # empty x-axis label (we'll customize it below)\n     ylab = \"Private rents â€” annual % change\",  # y-axis label\n     main = \"UK private rents (PIPR): annual % change\",  # chart title\n     xaxt = \"n\")  # suppress default x-axis (we'll add custom labels)\n\n# Add sparse x-axis labels (every 6th data point to avoid overcrowding)\nlabs_every &lt;- 6  # show a label every 6 months\nat_idx &lt;- seq(1, nrow(pipr), by = labs_every)  # create sequence of index positions\naxis(1,  # 1 means x-axis (bottom)\n     at = at_idx,  # positions where labels appear\n     labels = pipr$month[at_idx],  # the actual month labels\n     las = 2,  # rotate labels perpendicular to axis\n     cex.axis = 0.7)  # make label font smaller (70% of default)\n\n# Add subtitle showing data source directly under the title\ntitle(sub = \"Source: ONS - Index of Private Housing Rental Prices (PIPR)\", \n      cex.sub = 0.8,  # 80% of normal text size\n      font.sub = 3)  # 3 means italic font\n\n# Add horizontal reference line at 2% (Bank of England inflation target)\nabline(h = 2,  # horizontal line at y = 2\n       lty = 2,  # line type 2 = dashed\n       col = \"blue\")  # blue color\n\n# Add text label for the reference line\ntext(x = min(pipr$month),  # position at start of time series\n     y = 2,  # at the 2% level\n     labels = \"Inflation target (2%)\",  # the text to display\n     pos = 3,  # position 3 = above the point\n     col = \"blue\",  # match the line color\n     cex = 0.8)  # slightly smaller text (80% of default)\n\n\n\n\n\n\n\n\nğŸ’­ Reflect: Identify periods of fastest rent inflation and periods of slowdown. What macro factors might line up with these shifts?\n\n\n\nPart E â€” Import PIPR as CSV (alternative)\nRecall we downloaded the CSV version from the PIPR page. Import the file with readr::read_csv().\n\n# Open the library to read csv comma delimited files.\nlibrary(readr)\n# Create the object pipr_csv to store the data\npipr_csv &lt;- read_csv(\"data/pipr_monthly.csv\", skip =7)  # adjust file name\n\nRows: 116 Columns: 6\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (1): Date\ndbl (5): UK, England, Wales, Scotland, Northern Ireland\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# colums/variable names\nnames(pipr_csv)\n\n[1] \"Date\"             \"UK\"               \"England\"          \"Wales\"           \n[5] \"Scotland\"         \"Northern Ireland\"\n\n# quick overview of the data (tibble)\nhead(pipr_csv)\n\n# A tibble: 6 Ã— 6\n  Date      UK England Wales Scotland `Northern Ireland`\n  &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;              &lt;dbl&gt;\n1 Jan-16   3.3     3.5   1.2      2.1                1.1\n2 Feb-16   3.3     3.5   0.8      1.8                1.3\n3 Mar-16   3.4     3.6   0.8      1.6                1.4\n4 Apr-16   3.3     3.5   0.6      1.5                1.6\n5 May-16   3.2     3.3   0.4      1.4                1.6\n6 Jun-16   3.3     3.5   0.3      1.1                1.6\n\n\n\n\n\nPart G â€” Compare UK with a region\nThe workbook includes regions (England, Wales, Scotland, Northern Ireland), select one annual % change column and plot together with the UK.\n\nplot(\n    pipr$uk, type = \"l\", lwd = 2,\n    xlab = \"Month\", ylab = \"Annual % change\",\n    main = \"PIPR annual % change: UK vs UK countries to Aug 2025\",\n    ylim = c(0,12)\n  )\n# Use the function 'lines' to add the time series to the initial plot.\nlines(pipr$england, lwd= 1, col=\"red\")\nlines(pipr$scotland, lwd= 1, col=\"blue\")\nlines(pipr$wales, lwd= 1, col=\"green\")\nlines(pipr$n_ireland, lwd= 1, col=\"grey\")\n\nlegend(\n  \"topleft\",\n  legend = c(\"UK\", \"England\", \"Scotland\", \"Wales\", \"N. Ireland\"),\n  col    = c(\"black\", \"red\", \"blue\", \"green\", \"grey\"),\n  lwd    = c(2, 1, 1, 1, 1),\n  lty    = 1,\n  bty    = \"n\"       # no box around legend (optional)\n  # inset = 0.02     # nudge inward if needed\n)\n\n\n\n\n\n\n\n\nğŸ’­ Reflect: Did the countries move broadly with the UK or diverge materially? What local factors could explain divergence?\n\n\n\nPart H â€” Help pages and plotting extras\nLetâ€™s explore ?plot in the console. This will launch a help page in the help tab.\nWe also explore curve() and abline().\n\n# ?plot   # open during interactive session\ncurve(sin(x), from = 0, to = 6.28, xlab = \"x\", ylab = \"y = sin(x)\")\nabline(h = 0, v = 5, lty = 2)\n\n\n\n\n\n\n\n\nğŸ’­ Reflect: Which plot() arguments improved readability most? Explain the use of las, xaxt, lwd, and xlim.\n\n\n\nPart I â€” Access the data of â€˜Principles of Econometricsâ€™\nYou can also explore textbook datasets with PoEdata for practice with scatter plots and abline(lm()).\n\n#install.packages(c(\"remotes\", \"pkgbuild\"))   # helper packages\n#pkgbuild::has_build_tools(debug = TRUE)       # should say TRUE on Windows\n#remotes::install_github(\"ccolonescu/PoEdata\")\nlibrary(PoEdata)\ndata()\ndata(\"andy\")\nhead(andy)\n\n  sales price advert\n1  73.2  5.69    1.3\n2  71.8  6.49    2.9\n3  62.4  5.63    0.8\n4  67.4  6.22    0.7\n5  89.3  5.02    1.5\n6  70.3  6.41    1.3\n\n\n\n\n\nBest practices\n\nReproducibility: Prefer code over manual spreadsheet edits; paste RStudioâ€™s generated import code into your script.\nPaths & naming: Use a data/ subfolder; avoid spaces; use forward slashes.\nTypes & missing values: Check with str(), summary(), anyNA(); coerce explicitly when needed.\nAxis labelling: Sparse, rotated labels help on monthly series.\nVersioning: Save dated copies of raw downloads (e.g., pipr_monthly_2025-09-19.xlsx).\n\n\nğŸ End of Lab 4\nğŸ›‘ Remember to save your script ğŸ’¾",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Supervision 1</span>"
    ]
  },
  {
    "objectID": "supervision_1.html#lab-5-data-visualisation",
    "href": "supervision_1.html#lab-5-data-visualisation",
    "title": "Supervision 1",
    "section": "ğŸ§ª Lab 5 â€” Data Visualisation",
    "text": "ğŸ§ª Lab 5 â€” Data Visualisation\nAdapted from: A Guide to Data Visualisation in R for Beginners\n\n\nLearning outcomes\nBy the end of this lab you will be able to:\n\nExplore the state.x77 dataset in R.\nGenerate basic descriptive statistics.\nCreate simple plots using base R graphics.\nAdd labels, titles, and colours to plots.\nCompare different chart types (scatter, bar, histogram, boxplot).\nUse multi-panel displays to visualise multiple plots at once.\n\n\n\n\nPrerequisites\n\nR (â‰¥ 4.0) and RStudio.\nNo additional packages required beyond base R (optional: ggplot2 for comparison).\n\n\n\n\nPart A â€” Load dataset\n\nlibrary(datasets)\nstate_data &lt;- as.data.frame(datasets::state.x77)\nView(state_data)\n\n\n\n\nPart B â€” Data exploration\n\nstr(state_data)\n\n'data.frame':   50 obs. of  8 variables:\n $ Population: num  3615 365 2212 2110 21198 ...\n $ Income    : num  3624 6315 4530 3378 5114 ...\n $ Illiteracy: num  2.1 1.5 1.8 1.9 1.1 0.7 1.1 0.9 1.3 2 ...\n $ Life Exp  : num  69 69.3 70.5 70.7 71.7 ...\n $ Murder    : num  15.1 11.3 7.8 10.1 10.3 6.8 3.1 6.2 10.7 13.9 ...\n $ HS Grad   : num  41.3 66.7 58.1 39.9 62.6 63.9 56 54.6 52.6 40.6 ...\n $ Frost     : num  20 152 15 65 20 166 139 103 11 60 ...\n $ Area      : num  50708 566432 113417 51945 156361 ...\n\n\nğŸ’­ Reflect: Explore possible research aims from the state.x77 dataset. What variables are present in state.x77? How many states (rows) and variables (columns) are there? Which are continuous, and which categorical (if any)?\n\n\n\nPart C â€” Beginning and end of the dataset\n\nhead(state_data, 7)\n\n            Population Income Illiteracy Life Exp Murder HS Grad Frost   Area\nAlabama           3615   3624        2.1    69.05   15.1    41.3    20  50708\nAlaska             365   6315        1.5    69.31   11.3    66.7   152 566432\nArizona           2212   4530        1.8    70.55    7.8    58.1    15 113417\nArkansas          2110   3378        1.9    70.66   10.1    39.9    65  51945\nCalifornia       21198   5114        1.1    71.71   10.3    62.6    20 156361\nColorado          2541   4884        0.7    72.06    6.8    63.9   166 103766\nConnecticut       3100   5348        1.1    72.48    3.1    56.0   139   4862\n\ntail(state_data, 5)\n\n              Population Income Illiteracy Life Exp Murder HS Grad Frost  Area\nVirginia            4981   4701        1.4    70.08    9.5    47.8    85 39780\nWashington          3559   4864        0.6    71.72    4.3    63.5    32 66570\nWest Virginia       1799   3617        1.4    69.48    6.7    41.6   100 24070\nWisconsin           4589   4468        0.7    72.48    3.0    54.5   149 54464\nWyoming              376   4566        0.6    70.29    6.9    62.9   173 97203\n\n\n\n\n\nPart D â€” Descriptive statistics\nThere are several functions to obtain descriptive statistics, summary, psych, skimr, etc.\nHere is an example with summary.\n\nsummary(state_data)\n\n   Population        Income       Illiteracy       Life Exp    \n Min.   :  365   Min.   :3098   Min.   :0.500   Min.   :67.96  \n 1st Qu.: 1080   1st Qu.:3993   1st Qu.:0.625   1st Qu.:70.12  \n Median : 2838   Median :4519   Median :0.950   Median :70.67  \n Mean   : 4246   Mean   :4436   Mean   :1.170   Mean   :70.88  \n 3rd Qu.: 4968   3rd Qu.:4814   3rd Qu.:1.575   3rd Qu.:71.89  \n Max.   :21198   Max.   :6315   Max.   :2.800   Max.   :73.60  \n     Murder          HS Grad          Frost             Area       \n Min.   : 1.400   Min.   :37.80   Min.   :  0.00   Min.   :  1049  \n 1st Qu.: 4.350   1st Qu.:48.05   1st Qu.: 66.25   1st Qu.: 36985  \n Median : 6.850   Median :53.25   Median :114.50   Median : 54277  \n Mean   : 7.378   Mean   :53.11   Mean   :104.46   Mean   : 70736  \n 3rd Qu.:10.675   3rd Qu.:59.15   3rd Qu.:139.75   3rd Qu.: 81163  \n Max.   :15.100   Max.   :67.30   Max.   :188.00   Max.   :566432  \n\n\nAnd, another example with the package psych.\n\n#install.packages(\"psych\")   # if not already installed\nlibrary(psych)\n\ndescribe(state_data)\n\n           vars  n     mean       sd   median  trimmed      mad     min\nPopulation    1 50  4246.42  4464.49  2838.50  3384.28  2890.33  365.00\nIncome        2 50  4435.80   614.47  4519.00  4430.08   581.18 3098.00\nIlliteracy    3 50     1.17     0.61     0.95     1.10     0.52    0.50\nLife Exp      4 50    70.88     1.34    70.67    70.92     1.54   67.96\nMurder        5 50     7.38     3.69     6.85     7.30     5.19    1.40\nHS Grad       6 50    53.11     8.08    53.25    53.34     8.60   37.80\nFrost         7 50   104.46    51.98   114.50   106.80    53.37    0.00\nArea          8 50 70735.88 85327.30 54277.00 56575.72 35144.29 1049.00\n                max     range  skew kurtosis       se\nPopulation  21198.0  20833.00  1.92     3.75   631.37\nIncome       6315.0   3217.00  0.20     0.24    86.90\nIlliteracy      2.8      2.30  0.82    -0.47     0.09\nLife Exp       73.6      5.64 -0.15    -0.67     0.19\nMurder         15.1     13.70  0.13    -1.21     0.52\nHS Grad        67.3     29.50 -0.32    -0.88     1.14\nFrost         188.0    188.00 -0.37    -0.94     7.35\nArea       566432.0 565383.00  4.10    20.39 12067.10\n\n\nHowever, some users writing research might want more elaborated outputs.\n\nlibrary(dplyr)\nlibrary(gtsummary)\nlibrary(flextable)\n\n# Recreate data inside this chunk (Quarto runs in a clean session)\nstate_data &lt;- as.data.frame(datasets::state.x77)\nstate_data$region &lt;- factor(datasets::state.region)  # add stratifier\nnames(state_data) &lt;- make.names(names(state_data))   # Life.Exp, HS.Grad, etc.\n\ntbl &lt;- state_data |&gt;\n  gtsummary::tbl_summary(\n    by = region,\n    type = gtsummary::all_continuous() ~ \"continuous2\",\n    statistic = gtsummary::all_continuous() ~ c(\"{mean} ({sd})\", \"{median} [{p25}, {p75}]\"),\n    digits = gtsummary::all_continuous() ~ 1,\n    missing = \"ifany\",\n    label = list(\n      Income ~ \"Per-capita Income\",\n      Illiteracy ~ \"Illiteracy (%)\",\n      Life.Exp ~ \"Life Expectancy\",\n      Murder ~ \"Murder Rate\",\n      HS.Grad ~ \"High-School Grad (%)\",\n      Frost ~ \"Frost Days\",\n      Area ~ \"Area (sq mi)\"\n    )\n  ) |&gt;\n  gtsummary::add_overall(last = TRUE) |&gt;\n  gtsummary::add_p() |&gt;\n  gtsummary::bold_labels() |&gt;\n  gtsummary::modify_caption(\"**Table: Descriptive statistics by region**\")\n\ntbl\n\n\n\nTableÂ 2.1: Table: Descriptive statistics by region\n\n\n\n\n\n\n\nTable: Descriptive statistics by region\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nNortheast\nN = 9\nSouth\nN = 16\nNorth Central\nN = 12\nWest\nN = 13\nOverall\nN = 50\np-value1\n\n\n\n\nPopulation\n\n\n\n\n\n\n\n\n\n\n0.054\n\n\nÂ Â Â Â Mean (SD)\n5,495.1 (6,079.6)\n4,208.1 (2,779.5)\n4,803.0 (3,702.8)\n2,915.3 (5,578.6)\n4,246.4 (4,464.5)\n\n\n\n\nÂ Â Â Â Median [Q1, Q3]\n3,100.0 [931.0, 7,333.0]\n3,710.5 [2,528.0, 4,956.0]\n4,255.0 [1,912.0, 7,212.0]\n1,144.0 [746.0, 2,284.0]\n2,838.5 [1,058.0, 4,981.0]\n\n\n\n\nPer-capita Income\n\n\n\n\n\n\n\n\n\n\n0.019\n\n\nÂ Â Â Â Mean (SD)\n4,570.2 (559.1)\n4,011.9 (605.5)\n4,611.1 (283.1)\n4,702.6 (663.9)\n4,435.8 (614.5)\n\n\n\n\nÂ Â Â Â Median [Q1, Q3]\n4,558.0 [4,281.0, 4,903.0]\n3,848.0 [3,620.5, 4,444.5]\n4,594.5 [4,463.0, 4,713.0]\n4,660.0 [4,347.0, 4,963.0]\n4,519.0 [3,983.0, 4,815.0]\n\n\n\n\nIlliteracy (%)\n\n\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\nÂ Â Â Â Mean (SD)\n1.0 (0.3)\n1.7 (0.6)\n0.7 (0.1)\n1.0 (0.6)\n1.2 (0.6)\n\n\n\n\nÂ Â Â Â Median [Q1, Q3]\n1.1 [0.7, 1.1]\n1.8 [1.4, 2.2]\n0.7 [0.6, 0.8]\n0.6 [0.6, 1.5]\n1.0 [0.6, 1.6]\n\n\n\n\nLife Expectancy\n\n\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\nÂ Â Â Â Mean (SD)\n71.3 (0.7)\n69.7 (1.0)\n71.8 (1.0)\n71.2 (1.4)\n70.9 (1.3)\n\n\n\n\nÂ Â Â Â Median [Q1, Q3]\n71.2 [70.6, 71.8]\n70.1 [68.9, 70.4]\n72.3 [70.8, 72.6]\n71.7 [70.3, 72.1]\n70.7 [70.1, 71.9]\n\n\n\n\nMurder Rate\n\n\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\nÂ Â Â Â Mean (SD)\n4.7 (2.7)\n10.6 (2.6)\n5.3 (3.6)\n7.2 (2.7)\n7.4 (3.7)\n\n\n\n\nÂ Â Â Â Median [Q1, Q3]\n3.3 [3.1, 5.5]\n10.9 [9.0, 12.4]\n3.8 [2.3, 8.4]\n6.8 [5.0, 9.7]\n6.9 [4.3, 10.7]\n\n\n\n\nHigh-School Grad (%)\n\n\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\nÂ Â Â Â Mean (SD)\n54.0 (3.9)\n44.3 (5.7)\n54.5 (3.6)\n62.0 (3.5)\n53.1 (8.1)\n\n\n\n\nÂ Â Â Â Median [Q1, Q3]\n54.7 [52.5, 57.1]\n41.7 [40.3, 49.7]\n53.3 [52.7, 58.3]\n62.6 [59.5, 63.9]\n53.3 [47.8, 59.2]\n\n\n\n\nFrost Days\n\n\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\nÂ Â Â Â Mean (SD)\n132.8 (30.9)\n64.6 (31.3)\n138.8 (23.9)\n102.2 (68.9)\n104.5 (52.0)\n\n\n\n\nÂ Â Â Â Median [Q1, Q3]\n127.0 [115.0, 161.0]\n67.5 [42.5, 90.0]\n133.0 [123.0, 154.5]\n126.0 [32.0, 155.0]\n114.5 [65.0, 140.0]\n\n\n\n\nArea (sq mi)\n\n\n\n\n\n\n\n\n\n\n&lt;0.001\n\n\nÂ Â Â Â Mean (SD)\n18,141.0 (18,075.7)\n54,605.1 (57,965.3)\n62,652.0 (14,967.0)\n134,463.0 (134,981.7)\n70,735.9 (85,327.3)\n\n\n\n\nÂ Â Â Â Median [Q1, Q3]\n9,027.0 [7,521.0, 30,920.0]\n46,113.0 [34,937.5, 53,017.5]\n62,906.0 [55,106.0, 76,219.0]\n103,766.0 [82,677.0, 121,412.0]\n54,277.0 [36,097.0, 81,787.0]\n\n\n\n\n\n1 Kruskal-Wallis rank sum test\n\n\n\n\n\n\n\n\n\n\n\nğŸ’­ Reflect: Which socio-economic indicators show the widest spread?\n\n\n\nPart E â€” Graphics package\nReview other type of graphics or plotting functions that can be useful for land economy research. The folloging code opens a new tab with more details.\n\nlibrary(help = \"graphics\")\n\n\n\n\nPart F â€” Scatterplots\n\nplot(state_data$Income, state_data$Illiteracy)\n\n\n\n\n\n\n\n\nğŸ’­ Reflect: Do states with higher income tend to have lower illiteracy rates?\n\n\n\nPart G â€” Entire dataset plot\n\nplot(state_data)\n\n\n\n\n\n\n\n\nğŸ’­ Reflect: Which pairs of socio-economic indicators appear strongly related?\n\n\n\nPart H â€” Points and lines\n\nplot(state_data$Life.Exp, type = \"b\")\n\n\n\n\n\n\n\nplot(state_data$Life.Exp, type = \"h\")\n\n\n\n\n\n\n\n\nğŸ’­ Reflect: Which representation communicates variation in life expectancy more clearly?\n\n\n\nPart J â€” Help\n\n?plot\n\nstarting httpd help server ... done\n\n\nğŸ’­ Reflect: Identify one new argument from the help page that could improve your plot.\n\n\n\nPart K â€” Labels and titles\n\nplot(state_data$Income,\n     xlab = \"State Index\",\n     ylab = \"Per Capita Income\",\n     main = \"Income levels across US states\",\n     col = \"blue\")\n\n\n\n\n\n\n\n\nğŸ’­ Reflect: Do the labels improve clarity? Suggest improvements if needed.\n\n\n\nPart L â€” Horizontal bar plot\n\n# Take the Murder column as a named vector (names = state names)\nm &lt;- state_data$Murder\nnames(m) &lt;- rownames(state_data)\n\n# Pick the top 10 states by murder rate (highest first)â€¦\nm_top &lt;- sort(m, decreasing = TRUE)[1:10]\n# â€¦then re-sort ascending so the biggest bar appears at the TOP in a horizontal plot\nm_top &lt;- sort(m_top)\n\n# Make the plot: horizontal bars, tidy labels\nbp &lt;- barplot(\n  m_top,                                # bar heights (uses names(m_top) as labels)\n  horiz = TRUE,                         # horizontal bars\n  las = 1,                              # horizontal axis labels\n  cex.names = 0.8,                      # slightly smaller labels\n  space = 0.02,                         # small gaps between bars\n  col = rainbow(length(m_top)),         # one colour per bar (top 10 only)\n  main = \"Top 10 States by Murder Rate\",\n  xlab = \"Murder arrests per 100,000\",\n  xlim = c(0, max(m_top) * 1.1)         # a bit of right padding\n)\n\n\n\n\n\n\n\n\nğŸ’­ Reflect: - Which states stand out with particularly high murder rates? - Can you adapt the script to barplot the 10 states with lower murder rates?\n\n\n\nPart M â€” Vertical bar plot\nWe could use the previous script to barplot vertically by changing the option from horiz = TRUE to horiz = FALSEas in the following routine/code.\n\nbarplot(state_data$Illiteracy,\n        main = \"Illiteracy Rate by State\",\n        xlab = \"% Illiteracy\",\n        col = \"orange\",\n        horiz = FALSE)\n\n\n\n\n\n\n\n\nğŸ’­ Reflect: How might this plot inform discussions on educational policy?\n\n\n\nPart N â€” Histograms\n\nhist(state_data$Income,\n     main = \"Distribution of State Incomes\",\n     xlab = \"Per Capita Income\",\n     col = \"green\")\n\n\n\n\n\n\n\n\nğŸ’­ Reflect: Is the income distribution symmetric, skewed, or multi-modal?\n\n\n\nPart O â€” Boxplots\n\nboxplot(state_data$Life.Exp)\n\n\n\n\n\n\n\n\nğŸ’­ Reflect: What does the boxplot reveal about state-level life expectancy?\n\n\n\nPart P â€” Multiple boxplots\n\nboxplot(state_data[, c(\"Life.Exp\", \"Murder\", \"HS.Grad\", \"Frost\")],\n        main = \"Socio-economic Indicators across States\")\n\n\n\n\n\n\n\n\nğŸ’­ Reflect: Which variable shows the most variability? The least?\n\n\n\nPart Q â€” Grid of charts\nWe can create a grid of charts with the function par; (3,3) means a grid made of 3 rows x 3 columns.\n\npar(mfrow = c(3,3), mar = c(2,5,2,1), las = 1, bty = \"n\")\n\nplot(state_data$Population)\nplot(state_data$Income, state_data$Illiteracy)\nplot(state_data$Life.Exp, type = \"c\")\nplot(state_data$Life.Exp, type = \"s\")\nplot(state_data$Life.Exp, type = \"h\")\n\nbarplot(state_data$Income, main = \"Income levels\", col = \"blue\", horiz = TRUE)\nhist(state_data$Murder)\nboxplot(state_data$HS.Grad)\nboxplot(state_data[, c(\"Population\", \"Income\", \"Illiteracy\", \n\"Life.Exp\")], main = \"Multiple Box plots\")\n\n\n\n\n\n\n\n\n\n\n\nBest practices\n\nAlways check the structure of socio-economic data before plotting.\nMatch plot type to variable type.\nAdd descriptive titles and labels.\nAvoid misleading graphics (bar plots for continuous data should be used cautiously).\nVisualise relationships before modelling.\n\n\n\n\nFurther visualisation packages\n\nlattice: kernel density plots\nggplot2: flexible grammar of graphics\nplotly: interactive plots\nmaps: plot country maps\n\nMore resources: towardsdatascience.com article\n\nğŸ End of Lab 5 ğŸ›‘ Remember to save your script ğŸ’¾",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Supervision 1</span>"
    ]
  },
  {
    "objectID": "supervision_1.html#lab-6-using-github-copilot-in-rstudio",
    "href": "supervision_1.html#lab-6-using-github-copilot-in-rstudio",
    "title": "Supervision 1",
    "section": "ğŸ§ª Lab 6 â€” Using GitHub Copilot in RStudio",
    "text": "ğŸ§ª Lab 6 â€” Using GitHub Copilot in RStudio\n\nGoal\nLearn to use GitHub Copilot inside RStudio to speed up routine coding, while staying in control of quality, privacy, and reproducibility.\n\n\n\nLearning outcomes\nBy the end you will be able to:\n\nEnable and sign into GitHub Copilot in RStudio.\nAccept, reject, or modify Copilot autocomplete suggestions effectively.\nUse comment-first prompting to steer suggestions.\nDiagnose and fix typical Copilot mistakes (wrong column names, redundant args, etc.).\nApply safe-use practices (privacy, determinism, avoiding â€œvibe codingâ€).\n\n\n\n\nPrerequisites\n\nR (â‰¥ 4.3 recommended) and RStudio (a recent version with Copilot support).\nA GitHub account with Copilot access (student/educator plans are available).\nPackages: tidyverse, palmerpenguins, readxl, ggplot2.\n\ninstall.packages(c(\"tidyverse\", \"palmerpenguins\", \"readxl\", \"ggplot2\"))\n\nNote: Column names for the penguins dataset may differ depending on source. Treat this as a feature to practice Copilot-aware debugging.\n\n\n\n\nPart A â€” Set up Copilot in RStudio\n\nOpen RStudio â†’ Tools â†’ Global Options â†’ Copilot.\nEnable GitHub Copilot and sign in with GitHub.\nCreate a new R Script (File â†’ New File â†’ R Script).\nType some characters to see ghost text suggestions.\n\nTab to accept, Esc to dismiss, or keep typing to ignore.\n\n\n\n\nReflection A\nExplain in one sentence the difference between ghost text and code youâ€™ve actually inserted.\n\n\n\nPart B â€” First suggestions with ggplot2 (20 min)\nWeâ€™ll use penguins to practice.\n\nAdd a guiding comment:\n\n# Task: scatter plot of bill length (x) vs body mass (y), colour by species\n\nStart a plot:\n\nlibrary(ggplot2)\n# library(palmerpenguins)\n# penguins &lt;- palmerpenguins::penguins\n\np &lt;- ggplot(penguins, aes(x = bill_length_mm, y = body_mass_g, colour = species)) +\n  geom_point()\n\nRun and, if errors occur, inspect:\n\nglimpse(penguins)\nnames(penguins)\n\nFix names if needed (bill_length_mm â†’ bill_len).\n\n\n\nMini-exercises\n\nAdd title, caption, and axis labels:\n\n# Add a title, caption, and nicer axis labels\n\nAdd smoother:\n\n# Add a loess smoother without confidence band\n\n\nReflection B\nWhen is Copilot faster? When slower?\n\n\n\nPart C â€” Comment-first prompting for histograms\n\nAdd a guiding comment:\n\n# Histogram of body mass by species, overlapping with transparency and an accessible palette\n\nInspect Copilotâ€™s suggestion, remove redundant arguments, and adjust to:\n\ngeom_histogram(position = \"identity\", alpha = 0.5)\n\nCommit the cleaned version.\n\n\n\nReflection C\nReplace colour with fill, adjust legend, apply minimal theme.\n\n\n\nPart D â€” Loading local data safely\nCopilot does not know your file system.\n\nSave Scooby.xlsx in a data/ folder.\nLoad explicitly:\n\nlibrary(readxl)\nscooby &lt;- read_xlsx(\"data/Scooby.xlsx\")\n\nAdd prompt:\n\n# Quick EDA: glimpse, summary, and count episodes by network\n\nEdit Copilotâ€™s code before running.\n\n\n\nReflection D\nWhy be explicit with data loading and library imports?\n\n\n\nPart E â€” Boxplots\nVisualise IMDb ratings by network.\n\nPrompt:\n\n# Boxplot of IMDb (y) by network (x); tilt x labels; use fill instead of colour\n\nEdit column names if needed.\nAdd improvements:\n\n# Make it horizontal, tidy legend, and add labs\n\n\nExtension E\nOrder networks by median rating.\n\n\n\nPart F â€” Best practices\n\nPrivacy: Never expose credentials/confidential data.\nNon-determinism: Review suggestions before accepting.\nNo vibe coding: Donâ€™t accept what you donâ€™t understand.\nContext helps: Use clean code and comments.\nReproducibility: Remove redundant args, consider renv.\n\ninstall.packages(\"renv\")\nrenv::init()\n\n\n\nPart G â€” Check-off & submission\n\nCopilot enabled and signed in.\nOne scatter plot (corrected column names).\nOne histogram (transparency + accessible palette).\nOne boxplot (labels/theme improved).\nReflection paragraph on Copilot.\n\n\n\n\nTA rubric\n\nSetup (10%): Copilot enabled; script compiles.\nCode quality (40%): Reviewed/edited suggestions; correct names.\nVisuals (30%): Clear labels, sensible themes.\nReflection (20%): Insightful, acknowledges limits.\n\n\n\n\nTroubleshooting\n\nSuggestions not appearing? Check Global Options â†’ Copilot.\nWrong dataset/columns? Run names()/glimpse().\nOverconfident code? Scale back, test small steps.\n\n\n\n\nFurther practice\n\nRewrite prompts as comments for grouped summaries, joins, faceted plots.\nCompare Copilot vs manual solutions.\n\n\nğŸ End of lab 6 ğŸ›‘ Remember to save your script ğŸ’¾",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Supervision 1</span>"
    ]
  },
  {
    "objectID": "supervision_2.html",
    "href": "supervision_2.html",
    "title": "Supervision 2",
    "section": "",
    "text": "ğŸ§ª Lab 7 â€” The Simple Linear Regression Model",
    "crumbs": [
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Supervision 2</span>"
    ]
  },
  {
    "objectID": "supervision_2.html#lab-7-the-simple-linear-regression-model",
    "href": "supervision_2.html#lab-7-the-simple-linear-regression-model",
    "title": "Supervision 2",
    "section": "",
    "text": "ğŸ¯ Learning outcomes\nBy the end of this lab you will be able to:\n\nUnderstand the mathematical formulation of the simple linear regression model\nEstimate regression coefficients using lm() in R\nInterpret the intercept and slope parameters in an applied context\nExtract and examine regression output using summary() and related functions\nVisualize the fitted regression line on a scatter plot\nAssess the quality of model fit using residuals and R-squared\n\n\n\n\nğŸ§° Prerequisites\n\nR (â‰¥ 4.0) and RStudio installed\nCompleted Labs 1-6\nPackages (install once):\n\ninstall.packages(c(\"remotes\", \"PoEdata\"))\nremotes::install_github(\"ccolonescu/PoEdata\")\n\nSummary. In simple linear regression, we use one independent variable to predict a dependent variable. The relationship is represented by a straight line with an intercept and a slope.\nIntroduction. We explore the fundamentals of the Simple Linear Regression Model, a method to understand the relationship between two variables. This model is foundational for more advanced analyses.\nKey terms. The dependent variable \\((y)\\) is what we aim to predict; the independent variable, \\(x\\), explains \\(y\\).\n\n\nThe General Model\nAssume a linear relationship between the conditional expectation of (y) and (x):\n\\[\ny_i = \\beta_1 + \\beta_2 x_i + e_i \\tag{1}\n\\]\n\n\\(\\beta_1\\): intercept\n\\(\\beta_2\\): slope\n\n\\(e_i\\): error term with variance \\(\\sigma^2\\)\n\n\\(i=1,\\dots,N\\): observation index\n\nThe predicted (estimated) value of \\(y\\) given \\(x\\) is:\n\\[\n\\hat{y} = b_1 + b_2 x \\tag{2}\n\\]\nAssumptions:\n\nnon-random (x);\nconstant error variance (homoskedasticity);\nerrors uncorrelated across observations;\n\\(E[e_i \\mid x_i]=0\\).\n\n\nPART A. Example: Food Expenditure vs Income\n# Recall to install the package PoEdata once if needed:\ninstall.packages(\"remotes\")\nremotes::install_github(\"ccolonescu/PoEdata\")\n\nlibrary(PoEdata)\ndata(\"cps_small\")\nplot(cps_small$educ, cps_small$wage, xlab=\"Education\", ylab=\"Wage\")\n\n\n\n\n\n\n\n# Food data\ndata(\"food\")\nhead(food)\n\n  food_exp income\n1   115.22   3.69\n2   135.98   4.39\n3   119.34   4.75\n4   114.96   6.03\n5   187.05  12.47\n6   243.92  12.98\n\nplot(food$income, food$food_exp,\n     ylim=c(0, max(food$food_exp)),\n     xlim=c(0, max(food$income)),\n     xlab=\"weekly income in $100\", ylab=\"weekly food expenditure in $\",\n     type=\"p\")\n\n\n\n\n\n\n\n\n\n\nPART B. Estimating a Linear Regression\nFor the food data the model is\n\\[\n\\text{food\\_exp}_i = \\beta_1 + \\beta_2\\,\\text{income}_i + e_i.\\tag{3}\n\\]\n\nlibrary(PoEdata)\nmod1 &lt;- lm(food_exp ~ income, data = food)\nb1 &lt;- coef(mod1)[[1]]\nb2 &lt;- coef(mod1)[[2]]\nsmod1 &lt;- summary(mod1)\nsmod1\n\n\nCall:\nlm(formula = food_exp ~ income, data = food)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-223.025  -50.816   -6.324   67.879  212.044 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   83.416     43.410   1.922   0.0622 .  \nincome        10.210      2.093   4.877 1.95e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 89.52 on 38 degrees of freedom\nMultiple R-squared:  0.385, Adjusted R-squared:  0.3688 \nF-statistic: 23.79 on 1 and 38 DF,  p-value: 1.946e-05\n\n\nAdd the regression line to the scatter plot:\n\nplot(food$income, food$food_exp,\n     ylim=c(0, max(food$food_exp)),\n     xlim=c(0, max(food$income)),\n     xlab=\"weekly income in $100\", ylab=\"weekly food expenditure in $\",\n     type = \"p\")\nabline(b1, b2)\n\n\n\n\n\n\n\n\nRetrieve common results:\n\nnames(mod1)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\nnames(smod1)\n\n [1] \"call\"          \"terms\"         \"residuals\"     \"coefficients\" \n [5] \"aliased\"       \"sigma\"         \"df\"            \"r.squared\"    \n [9] \"adj.r.squared\" \"fstatistic\"    \"cov.unscaled\" \n\nmod1$coefficients\n\n(Intercept)      income \n   83.41600    10.20964 \n\nsmod1$coefficients\n\n            Estimate Std. Error  t value     Pr(&gt;|t|)\n(Intercept) 83.41600  43.410163 1.921578 6.218242e-02\nincome      10.20964   2.093264 4.877381 1.945862e-05\n\n\n\n\nPART C. MCQs\n\nWhat relationship does the simple linear regression assume between (y) and (x)?\nA. Quadratic Â Â  B. Logarithmic Â Â  C. Linear Â Â  D. Exponential\nIn Eq. (1), what is (_1)?\nA. Slope Â Â  B. Error term Â Â  C. Intercept Â Â  D. Dependent variable\nThe slope parameter indicates:\nA. Error variance Â Â  B. Change in (y) for a one-unit change in (x) Â Â  C. Intercept Â Â  D. Sample size\nâ€œResidualsâ€ are:\nA. Predicted (y) Â Â  B. (x) values Â Â  C. Observed minus predicted (y) Â Â  D. Coefficients\nsummary(mod1) is used to:\nA. List object names Â Â  B. Change coefficients Â Â  C. Plot the line Â Â  D. Display regression results\nEstimating with random subsamples primarily helps to:\nA. Change coefficients Â Â  B. Assess variability of coefficients Â Â  C. Increase N Â Â  D. Make the model nonâ€‘linear\nAdjusted (R^2) measures:\nA. Number of observations Â Â  B. Precision of intercept Â Â  C. Proportion of variance explained (adjusted) Â Â  D. SE of coefficients",
    "crumbs": [
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Supervision 2</span>"
    ]
  },
  {
    "objectID": "supervision_2.html#lab-8-prediction-with-the-linear-regression-model",
    "href": "supervision_2.html#lab-8-prediction-with-the-linear-regression-model",
    "title": "Supervision 2",
    "section": "ğŸ§ª Lab 8 â€” Prediction with the Linear Regression Model",
    "text": "ğŸ§ª Lab 8 â€” Prediction with the Linear Regression Model\nThe estimates (b_1) and (b_2) allow prediction via Eq. (2). Example: income = $2000 â†’ income = 20 (hundreds of dollars).\n\n# Model\nmod1 &lt;- lm(food_exp ~ income, data=food)\n\n# Predict at incomes = 2000, 2500, 2700 USD\nnewx &lt;- data.frame(income = c(20, 25, 27))\nyhat &lt;- predict(mod1, newx)\nnames(yhat) &lt;- c(\"income=$2000\", \"$2500\", \"$2700\")\nyhat\n\nincome=$2000        $2500        $2700 \n    287.6089     338.6571     359.0764 \n\n\n\nRepeated Samples to Assess Regression Coefficients\n\nN &lt;- nrow(food) # number of observations\nC &lt;- 50         # number of subsamples\nS &lt;- 38         # subsample size\n\nsumb2 &lt;- 0\nfor (i in 1:C){\n  set.seed(3*i)\n  subsample &lt;- food[sample(1:N, size=S, replace=TRUE), ]\n  mod2 &lt;- lm(food_exp ~ income, data=subsample)\n  sumb2 &lt;- sumb2 + coef(mod2)[[2]]\n}\nprint(sumb2/C, digits = 3)\n\n[1] 9.89\n\n\n\n\nEstimated Variances and Covariance of Coefficients\n\n(varb1 &lt;- vcov(mod1)[1, 1])\n\n[1] 1884.442\n\n(varb2 &lt;- vcov(mod1)[2, 2])\n\n[1] 4.381752\n\n(covb1b2 &lt;- vcov(mod1)[1, 2])\n\n[1] -85.90316\n\n\n\n\nNon-Linear Relationships\n\nQuadratic model\n\\[\ny_i = \\beta_1 + \\beta_2 x_i^2 + e_i.\\tag{5}\n\\]\n\nlibrary(PoEdata)\ndata(br)\nmod3 &lt;- lm(price ~ I(sqft^2), data=br)\nb1 &lt;- coef(mod3)[[1]]\nb2 &lt;- coef(mod3)[[2]]\n\nsqftx &lt;- c(2000, 4000, 6000)\npricex &lt;- b1 + b2*sqftx^2\nDpriceDsqft &lt;- 2*b2*sqftx\nelasticity &lt;- DpriceDsqft*sqftx/pricex\n\nb1; b2; DpriceDsqft; elasticity\n\n[1] 55776.57\n\n\n[1] 0.0154213\n\n\n[1]  61.68521 123.37041 185.05562\n\n\n[1] 1.050303 1.631251 1.817408\n\n\nPlotting alternatives:\n\nmod31 &lt;- lm(price ~ I(sqft^2), data=br)\nplot(br$sqft, br$price, xlab=\"Total square feet\", ylab=\"Sale price, $\", col=\"grey\")\ncurve(b1 + b2*x^2, add=TRUE)\n\n\n\n\n\n\n\n\n\nordat &lt;- br[order(br$sqft), ]\nmod31 &lt;- lm(price ~ I(sqft^2), data=ordat)\nplot(br$sqft, br$price, main=\"Dataset ordered after 'sqft'\",\n     xlab=\"Total square feet\", ylab=\"Sale price, $\", col=\"grey\")\nlines(fitted(mod31) ~ ordat$sqft)\n\n\n\n\n\n\n\n\n\n\nLog-linear model\n\\[\n\\log(y_i) = \\beta_1 + \\beta_2 x_i + e_i.\\tag{6}\n\\]\n\nhist(br$price)\n\n\n\n\n\n\n\nhist(log(br$price))\n\n\n\n\n\n\n\nmod4 &lt;- lm(log(price) ~ sqft, data=br)\nb1 &lt;- coef(mod4)[[1]]\nb2 &lt;- coef(mod4)[[2]]\n\n# Fitted curve on original price scale\nordat &lt;- br[order(br$sqft), ]\nmod4 &lt;- lm(log(price) ~ sqft, data=ordat)\nplot(br$sqft, br$price, col=\"grey\")\nlines(exp(fitted(mod4)) ~ ordat$sqft)\n\n\n\n\n\n\n\n\nElasticity and marginal effect at the median price:\n\npricex &lt;- median(br$price)\nsqftx &lt;- (log(pricex) - coef(mod4)[[1]])/coef(mod4)[[2]]\n(DyDx &lt;- pricex*coef(mod4)[[2]])\n\n[1] 53.46495\n\n(elasticity &lt;- sqftx*coef(mod4)[[2]])\n\n[1] 0.9366934\n\n\nMultiple points:\n\nb1 &lt;- coef(mod4)[[1]]\nb2 &lt;- coef(mod4)[[2]]\nsqftx &lt;- c(2000, 3000, 4000)\npricex &lt;- c(100000, exp(b1 + b2*sqftx))\nsqftx &lt;- (log(pricex) - b1)/b2\n(elasticities &lt;- b2*sqftx)\n\n[1] 0.6743291 0.8225377 1.2338066 1.6450754\n\n\n\n\nMCQs\n\nUsing (b_1) and (b_2) primarily helps to: B. Predict (E[yx])\n\nlm() is used to: C. Estimate a linear model\n\npredict() mainly: B. Estimates (y) for new data\n\nCoefficients are random because: C. They depend on the sample\n\nRandom subsamples help: C. Evaluate stability/variability\n\nvcov() is for: B. Variances and covariances of coefficients\n\ndata.frame() with predict() to: A. Format new (x) values",
    "crumbs": [
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Supervision 2</span>"
    ]
  },
  {
    "objectID": "supervision_2.html#lab-9-hypothesis-test-pvalue-testing-linear-combinations",
    "href": "supervision_2.html#lab-9-hypothesis-test-pvalue-testing-linear-combinations",
    "title": "Supervision 2",
    "section": "ğŸ§ª Lab 9 â€” Hypothesis Test, pâ€‘Value & Testing Linear Combinations",
    "text": "ğŸ§ª Lab 9 â€” Hypothesis Test, pâ€‘Value & Testing Linear Combinations\n\nHypothesis Tests\nNull vs alternative for a coefficient (_k):\n\\[\nH_0: \\beta_k = c, \\qquad H_A: \\beta_k \\ne c.\n\\]\nTest statistic: \\[\nt = \\frac{b_k - c}{\\operatorname{se}(b_k)},\\quad t \\sim t_{N-2}.\\tag{6}\n\\]\nExample for (b_2) in the food model:\n\nalpha &lt;- 0.05\nlibrary(PoEdata); library(xtable); library(knitr)\n\nWarning: package 'xtable' was built under R version 4.4.3\n\n\nWarning: package 'knitr' was built under R version 4.4.3\n\ndata(\"food\")\nmod1 &lt;- lm(food_exp ~ income, data=food); smod1 &lt;- summary(mod1)\n\ntable &lt;- data.frame(xtable(mod1))\nkable(table, caption=\"Regression output showing the coefficients\")\n\n\nRegression output showing the coefficients\n\n\n\nEstimate\nStd..Error\nt.value\nPrâ€¦t..\n\n\n\n\n(Intercept)\n83.41600\n43.410163\n1.921578\n0.0621824\n\n\nincome\n10.20964\n2.093263\n4.877381\n0.0000195\n\n\n\n\nb2 &lt;- coef(mod1)[[\"income\"]]\nseb2 &lt;- sqrt(vcov(mod1)[2,2])\ndf  &lt;- df.residual(mod1)\n\nt   &lt;- b2/seb2\ntcr &lt;- qt(1-alpha/2, df)\nt; tcr\n\n[1] 4.877381\n\n\n[1] 2.024394\n\n\nRightâ€‘tail and leftâ€‘tail versions:\n\n# Right-tail: H0: beta2 &lt;= 5.5; HA: beta2 &gt; 5.5\nc &lt;- 5.5\nt_right &lt;- (b2 - c)/seb2\ntcr_right &lt;- qt(1-alpha, df)\n\n# Left-tail: H0: beta2 &gt;= 15; HA: beta2 &lt; 15\nc &lt;- 15\nt_left &lt;- (b2 - c)/seb2\ntcr_left &lt;- qt(alpha, df)\n\nc(t_right=t_right, tcr_right=tcr_right, t_left=t_left, tcr_left=tcr_left)\n\n  t_right tcr_right    t_left  tcr_left \n 2.249904  1.685954 -2.288463 -1.685954 \n\n\n\n\nThe pâ€‘Value\nRightâ€‘tail: (p = 1 - F_t(t)). Leftâ€‘tail: (p = F_t(t)). Twoâ€‘tail: (p = 2(1-F_t(|t|))).\n\n# Right tail\nc &lt;- 5.5; t &lt;- (b2-c)/seb2; p_right &lt;- 1-pt(t, df)\n\n# Left tail\nc &lt;- 15; t &lt;- (b2-c)/seb2; p_left &lt;- pt(t, df)\n\n# Two tail\nc &lt;- 0;  t &lt;- (b2-c)/seb2; p_two &lt;- 2*(1-pt(abs(t), df))\n\nc(p_right=p_right, p_left=p_left, p_two=p_two)\n\n     p_right       p_left        p_two \n1.516329e-02 1.388071e-02 1.945862e-05 \n\n\n\n\nTesting Linear Combinations of Parameters\nExpected food expenditure at income = $2000 (i.e.Â (x=20)):\n\\[\nL = E(\\text{food\\_exp}\\mid \\text{income}=20) = \\beta_1 + 20\\,\\beta_2.\\tag{3.7}\n\\]\nVariance identities:\n\\[\n\\operatorname{var}(aX+bY) = a^2\\,\\operatorname{var}(X) + b^2\\,\\operatorname{var}(Y) + 2ab\\,\\operatorname{cov}(X,Y).\\tag{3.8}\n\\]\n\\[\n\\operatorname{var}(b_1+20b_2) = \\operatorname{var}(b_1) + 20^2\\operatorname{var}(b_2) + 2\\cdot20\\operatorname{cov}(b_1,b_2).\\tag{3.9}\n\\]\n\nalpha &lt;- 0.05; x &lt;- 20\nm1 &lt;- lm(food_exp ~ income, data=food)\ndf &lt;- df.residual(m1)\n\nb1 &lt;- m1$coef[1]; b2 &lt;- m1$coef[2]\nvarb1 &lt;- vcov(m1)[1,1]; varb2 &lt;- vcov(m1)[2,2]; covb1b2 &lt;- vcov(m1)[1,2]\n\nL &lt;- b1 + b2*x\nvarL &lt;- varb1 + x^2 * varb2 + 2*x*covb1b2\nseL &lt;- sqrt(varL)\n\ntcr &lt;- qt(1-alpha/2, df)\nlowbL &lt;- L - tcr*seL; upbL &lt;- L + tcr*seL\nc(L=L, seL=seL, low=lowbL, up=upbL)\n\n  L.(Intercept)             seL low.(Intercept)  up.(Intercept) \n      287.60886        14.17804       258.90692       316.31081 \n\n\nTwoâ€‘tail, leftâ€‘tail, rightâ€‘tail tests for (L):\n\nc &lt;- 250\nt &lt;- (L - c)/seL\np_value &lt;- 2*(1-pt(abs(t), df))\nc(t=t, p_value=p_value)\n\n      t.(Intercept) p_value.(Intercept) \n         2.65261316          0.01159078",
    "crumbs": [
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Supervision 2</span>"
    ]
  },
  {
    "objectID": "supervision_2.html#lab-10-the-pvalue-recap",
    "href": "supervision_2.html#lab-10-the-pvalue-recap",
    "title": "Supervision 2",
    "section": "ğŸ§ª Lab 10 â€” The pâ€‘Value (Recap)",
    "text": "ğŸ§ª Lab 10 â€” The pâ€‘Value (Recap)\n\nRightâ€‘tail: (p=1-pt(t,,df))\n\nLeftâ€‘tail: (p=pt(t,,df))\n\nTwoâ€‘tail: (p=2(1-pt(|t|,,df)))\n\n\n# Examples computed earlier are reproduced here:\nc(p_right=p_right, p_left=p_left, p_two=p_two)\n\n     p_right       p_left        p_two \n1.516329e-02 1.388071e-02 1.945862e-05 \n\n\n\n\nReferences\nAdkins (2014); Allaire et al.Â (2016); Colonescu (2016); Croissant & Millo (2015); Dahl (2016); Fox & Weisberg (2016); Fox et al.Â (2016); Ghalanos (2015); Graves (2014); Grolemund & Wickham (2016); Henningsen & Hamann (2015); Hill, Griffiths & Lim (2011); Hlavac (2015); Hothorn et al.Â (2015); Hyndman (2016); Kleiber & Zeileis (2015); Komashko (2016); Lander (2013); Lumley & Zeileis (2015); Pfaff (2013); R Core Team (2008); Reinhart (2015); Robinson (2016); RStudio Team (2015); Spada et al.Â (2012); Trapletti & Hornik (2016); Wickham & Chang (2016); Xie (2014, 2016a, 2016b); Zeileis (2016).",
    "crumbs": [
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Supervision 2</span>"
    ]
  },
  {
    "objectID": "supervision_3.html",
    "href": "supervision_3.html",
    "title": "Supervision 3",
    "section": "",
    "text": "Lab 1 â€” Data Prep for Variable Selection (Hitters)",
    "crumbs": [
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Supervision 3</span>"
    ]
  },
  {
    "objectID": "supervision_3.html#lab-1-data-prep-for-variable-selection-hitters",
    "href": "supervision_3.html#lab-1-data-prep-for-variable-selection-hitters",
    "title": "Supervision 3",
    "section": "",
    "text": "ğŸ¯ Learning outcomes\n\nLoad the Hitters data and inspect dimensions.\nHandle missing values (Salary) to avoid errors in model fitting.\nGet comfortable with the packages weâ€™ll use: ISLR and leaps.\n\n\n\nğŸ§° Prerequisites\n\nR and RStudio installed.\nPackages: ISLR, leaps.\n\n\n# install.packages(c(\"ISLR\",\"leaps\")) # if needed\nlibrary(ISLR)\n\nWarning: package 'ISLR' was built under R version 4.4.3\n\ndata(Hitters)\n\n# Inspect\nnames(Hitters)\n\n [1] \"AtBat\"     \"Hits\"      \"HmRun\"     \"Runs\"      \"RBI\"       \"Walks\"    \n [7] \"Years\"     \"CAtBat\"    \"CHits\"     \"CHmRun\"    \"CRuns\"     \"CRBI\"     \n[13] \"CWalks\"    \"League\"    \"Division\"  \"PutOuts\"   \"Assists\"   \"Errors\"   \n[19] \"Salary\"    \"NewLeague\"\n\ndim(Hitters)          # rows x columns\n\n[1] 322  20\n\nsum(is.na(Hitters$Salary))\n\n[1] 59\n\n# Drop rows with any NA (Salary has some NAs)\nHitters &lt;- na.omit(Hitters)\ndim(Hitters)\n\n[1] 263  20\n\nsum(is.na(Hitters))\n\n[1] 0\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe remove rows with missing Salary because selection routines (like regsubsets) require complete cases.",
    "crumbs": [
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Supervision 3</span>"
    ]
  },
  {
    "objectID": "supervision_3.html#lab-2-best-subset-selection",
    "href": "supervision_3.html#lab-2-best-subset-selection",
    "title": "Supervision 3",
    "section": "Lab 2 â€” Best Subset Selection",
    "text": "Lab 2 â€” Best Subset Selection\n\nğŸ¯ Learning outcomes\n\nFit best subset models with regsubsets().\nRetrieve the best model for each size.\nInspect classical metrics: RSS, RÂ², Adjusted RÂ², Cp, BIC.\n\n\nlibrary(leaps)\n\nWarning: package 'leaps' was built under R version 4.4.3\n\n# Exhaustive search over all subsets\nregfit.full &lt;- regsubsets(Salary ~ ., data = Hitters, nvmax = 19)\nreg.summary &lt;- summary(regfit.full)\n\n# What does summary() return?\nnames(reg.summary)\n\n[1] \"which\"  \"rsq\"    \"rss\"    \"adjr2\"  \"cp\"     \"bic\"    \"outmat\" \"obj\"   \n\n# Quick look at R^2 growth as we add variables\nreg.summary$rsq\n\n [1] 0.3214501 0.4252237 0.4514294 0.4754067 0.4908036 0.5087146 0.5141227\n [8] 0.5285569 0.5346124 0.5404950 0.5426153 0.5436302 0.5444570 0.5452164\n[15] 0.5454692 0.5457656 0.5459518 0.5460945 0.5461159\n\n\n\n\n\n\n\n\nTip\n\n\n\nregsubsets() searches the model space and stores the best model for each size (1..nvmax). Use summary() to see a which matrix and metrics across sizes.\n\n\n\n\nVisual diagnostics for choosing model size\n\npar(mfrow = c(2,2))\n\n# RSS\nplot(reg.summary$rss, xlab = \"Number of Variables\", ylab = \"RSS\", type = \"l\")\n\n# Adjusted R^2 (highlight maximum)\nplot(reg.summary$adjr2, xlab = \"Number of Variables\", ylab = \"Adjusted R^2\", type = \"l\")\nbest.adjr2 &lt;- which.max(reg.summary$adjr2)\npoints(best.adjr2, reg.summary$adjr2[best.adjr2], col = \"red\", cex = 2, pch = 20)\n\n# Cp (highlight minimum)\nplot(reg.summary$cp, xlab = \"Number of Variables\", ylab = \"Cp\", type = \"l\")\nbest.cp &lt;- which.min(reg.summary$cp)\npoints(best.cp, reg.summary$cp[best.cp], col = \"red\", cex = 2, pch = 20)\n\n# BIC (highlight minimum)\nplot(reg.summary$bic, xlab = \"Number of Variables\", ylab = \"BIC\", type = \"l\")\nbest.bic &lt;- which.min(reg.summary$bic)\npoints(best.bic, reg.summary$bic[best.bic], col = \"red\", cex = 2, pch = 20)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nRule of thumb: prefer the model size where Adjusted RÂ² peaks, or Cp/BIC are minimized. These are proxies for test error.\n\n\n\n\nInspect variables in the chosen model(s)\n\n# Example: variables in the BIC-optimal model\ncoef(regfit.full, best.bic)\n\n (Intercept)        AtBat         Hits        Walks         CRBI    DivisionW \n  91.5117981   -1.8685892    7.6043976    3.6976468    0.6430169 -122.9515338 \n     PutOuts \n   0.2643076 \n\n# regsubsets has its own plot helper:\nplot(regfit.full, scale = \"bic\")\n\n\n\n\n\n\n\nplot(regfit.full, scale = \"adjr2\")\n\n\n\n\n\n\n\nplot(regfit.full, scale = \"Cp\")\n\n\n\n\n\n\n\nplot(regfit.full, scale = \"r2\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Supervision 3</span>"
    ]
  },
  {
    "objectID": "supervision_3.html#lab-3-forward-stepwise-selection",
    "href": "supervision_3.html#lab-3-forward-stepwise-selection",
    "title": "Supervision 3",
    "section": "Lab 3 â€” Forward Stepwise Selection",
    "text": "Lab 3 â€” Forward Stepwise Selection\n\nğŸ¯ Learning outcomes\n\nRun forward stepwise selection using method = \"forward\".\nCompare chosen variables to best subset at the same size.\n\n\nregfit.fwd &lt;- regsubsets(Salary ~ ., data = Hitters, nvmax = 19, method = \"forward\")\nsummary(regfit.fwd)\n\nSubset selection object\nCall: regsubsets.formula(Salary ~ ., data = Hitters, nvmax = 19, method = \"forward\")\n19 Variables  (and intercept)\n           Forced in Forced out\nAtBat          FALSE      FALSE\nHits           FALSE      FALSE\nHmRun          FALSE      FALSE\nRuns           FALSE      FALSE\nRBI            FALSE      FALSE\nWalks          FALSE      FALSE\nYears          FALSE      FALSE\nCAtBat         FALSE      FALSE\nCHits          FALSE      FALSE\nCHmRun         FALSE      FALSE\nCRuns          FALSE      FALSE\nCRBI           FALSE      FALSE\nCWalks         FALSE      FALSE\nLeagueN        FALSE      FALSE\nDivisionW      FALSE      FALSE\nPutOuts        FALSE      FALSE\nAssists        FALSE      FALSE\nErrors         FALSE      FALSE\nNewLeagueN     FALSE      FALSE\n1 subsets of each size up to 19\nSelection Algorithm: forward\n          AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI\n1  ( 1 )  \" \"   \" \"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n2  ( 1 )  \" \"   \"*\"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n3  ( 1 )  \" \"   \"*\"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n4  ( 1 )  \" \"   \"*\"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n5  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n6  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n7  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \" \"    \" \"   \" \"    \" \"   \"*\" \n8  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \" \"    \" \"   \" \"    \"*\"   \"*\" \n9  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n10  ( 1 ) \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n11  ( 1 ) \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n12  ( 1 ) \"*\"   \"*\"  \" \"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n13  ( 1 ) \"*\"   \"*\"  \" \"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n14  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n15  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n16  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \" \"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n17  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \" \"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n18  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \"*\"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n19  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \"*\"   \"*\"    \"*\"   \"*\"    \"*\"   \"*\" \n          CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN\n1  ( 1 )  \" \"    \" \"     \" \"       \" \"     \" \"     \" \"    \" \"       \n2  ( 1 )  \" \"    \" \"     \" \"       \" \"     \" \"     \" \"    \" \"       \n3  ( 1 )  \" \"    \" \"     \" \"       \"*\"     \" \"     \" \"    \" \"       \n4  ( 1 )  \" \"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n5  ( 1 )  \" \"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n6  ( 1 )  \" \"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n7  ( 1 )  \"*\"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n8  ( 1 )  \"*\"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n9  ( 1 )  \"*\"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n10  ( 1 ) \"*\"    \" \"     \"*\"       \"*\"     \"*\"     \" \"    \" \"       \n11  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \" \"    \" \"       \n12  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \" \"    \" \"       \n13  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n14  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n15  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n16  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n17  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \"*\"       \n18  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \"*\"       \n19  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \"*\"       \n\n# Compare a specific size (e.g., 7 variables) across methods\ncoef(regfit.full, 7)  # best subset\n\n (Intercept)         Hits        Walks       CAtBat        CHits       CHmRun \n  79.4509472    1.2833513    3.2274264   -0.3752350    1.4957073    1.4420538 \n   DivisionW      PutOuts \n-129.9866432    0.2366813 \n\ncoef(regfit.fwd, 7)   # forward stepwise\n\n (Intercept)        AtBat         Hits        Walks         CRBI       CWalks \n 109.7873062   -1.9588851    7.4498772    4.9131401    0.8537622   -0.3053070 \n   DivisionW      PutOuts \n-127.1223928    0.2533404 \n\n\n\n\n\n\n\n\nWarning\n\n\n\nForward stepwise is greedy: after a variable enters, it stays. It evaluates far fewer models than best subsetâ€”great for speedâ€”but it may miss the global optimum.",
    "crumbs": [
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Supervision 3</span>"
    ]
  },
  {
    "objectID": "supervision_3.html#lab-4-backward-stepwise-selection",
    "href": "supervision_3.html#lab-4-backward-stepwise-selection",
    "title": "Supervision 3",
    "section": "Lab 4 â€” Backward Stepwise Selection",
    "text": "Lab 4 â€” Backward Stepwise Selection\n\nğŸ¯ Learning outcomes\n\nRun backward stepwise selection using method = \"backward\".\nUnderstand when backward is not applicable.\n\n\nregfit.bwd &lt;- regsubsets(Salary ~ ., data = Hitters, nvmax = 19, method = \"backward\")\nsummary(regfit.bwd)\n\nSubset selection object\nCall: regsubsets.formula(Salary ~ ., data = Hitters, nvmax = 19, method = \"backward\")\n19 Variables  (and intercept)\n           Forced in Forced out\nAtBat          FALSE      FALSE\nHits           FALSE      FALSE\nHmRun          FALSE      FALSE\nRuns           FALSE      FALSE\nRBI            FALSE      FALSE\nWalks          FALSE      FALSE\nYears          FALSE      FALSE\nCAtBat         FALSE      FALSE\nCHits          FALSE      FALSE\nCHmRun         FALSE      FALSE\nCRuns          FALSE      FALSE\nCRBI           FALSE      FALSE\nCWalks         FALSE      FALSE\nLeagueN        FALSE      FALSE\nDivisionW      FALSE      FALSE\nPutOuts        FALSE      FALSE\nAssists        FALSE      FALSE\nErrors         FALSE      FALSE\nNewLeagueN     FALSE      FALSE\n1 subsets of each size up to 19\nSelection Algorithm: backward\n          AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI\n1  ( 1 )  \" \"   \" \"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \"*\"   \" \" \n2  ( 1 )  \" \"   \"*\"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \"*\"   \" \" \n3  ( 1 )  \" \"   \"*\"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \"*\"   \" \" \n4  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \" \"   \" \"   \" \"    \" \"   \" \"    \"*\"   \" \" \n5  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \" \"    \" \"   \" \"    \"*\"   \" \" \n6  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \" \"    \" \"   \" \"    \"*\"   \" \" \n7  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \" \"    \" \"   \" \"    \"*\"   \" \" \n8  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \" \"    \" \"   \" \"    \"*\"   \"*\" \n9  ( 1 )  \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n10  ( 1 ) \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n11  ( 1 ) \"*\"   \"*\"  \" \"   \" \"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n12  ( 1 ) \"*\"   \"*\"  \" \"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n13  ( 1 ) \"*\"   \"*\"  \" \"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n14  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \" \"   \" \"    \"*\"   \"*\" \n15  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \" \" \"*\"   \" \"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n16  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \" \"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n17  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \" \"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n18  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \"*\"   \"*\"    \"*\"   \" \"    \"*\"   \"*\" \n19  ( 1 ) \"*\"   \"*\"  \"*\"   \"*\"  \"*\" \"*\"   \"*\"   \"*\"    \"*\"   \"*\"    \"*\"   \"*\" \n          CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN\n1  ( 1 )  \" \"    \" \"     \" \"       \" \"     \" \"     \" \"    \" \"       \n2  ( 1 )  \" \"    \" \"     \" \"       \" \"     \" \"     \" \"    \" \"       \n3  ( 1 )  \" \"    \" \"     \" \"       \"*\"     \" \"     \" \"    \" \"       \n4  ( 1 )  \" \"    \" \"     \" \"       \"*\"     \" \"     \" \"    \" \"       \n5  ( 1 )  \" \"    \" \"     \" \"       \"*\"     \" \"     \" \"    \" \"       \n6  ( 1 )  \" \"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n7  ( 1 )  \"*\"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n8  ( 1 )  \"*\"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n9  ( 1 )  \"*\"    \" \"     \"*\"       \"*\"     \" \"     \" \"    \" \"       \n10  ( 1 ) \"*\"    \" \"     \"*\"       \"*\"     \"*\"     \" \"    \" \"       \n11  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \" \"    \" \"       \n12  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \" \"    \" \"       \n13  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n14  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n15  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n16  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \" \"       \n17  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \"*\"       \n18  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \"*\"       \n19  ( 1 ) \"*\"    \"*\"     \"*\"       \"*\"     \"*\"     \"*\"    \"*\"       \n\n# Compare at size 7 again\ncoef(regfit.bwd, 7)   # backward stepwise\n\n (Intercept)        AtBat         Hits        Walks        CRuns       CWalks \n 105.6487488   -1.9762838    6.7574914    6.0558691    1.1293095   -0.7163346 \n   DivisionW      PutOuts \n-116.1692169    0.3028847 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nBackward stepwise starts from the full model and removes variables. It requires n &gt; p so that the full least squares fit exists.",
    "crumbs": [
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Supervision 3</span>"
    ]
  },
  {
    "objectID": "supervision_3.html#lab-5-reading-the-plots-coefficients-like-a-pro",
    "href": "supervision_3.html#lab-5-reading-the-plots-coefficients-like-a-pro",
    "title": "Supervision 3",
    "section": "Lab 5 â€” Reading the Plots & Coefficients Like a Pro",
    "text": "Lab 5 â€” Reading the Plots & Coefficients Like a Pro\n\nğŸ¯ Learning outcomes\n\nInterpret selection plots (BIC, Cp, Adjusted RÂ² panels).\nExtract and report the final model clearly.\n\n\n# Choose a final size by any one of the criteria\nk_final &lt;- best.bic     # example: BIC-minimizer\n\n# Coefficients and variables\nfinal_coef &lt;- coef(regfit.full, k_final)\nfinal_coef\n\n (Intercept)        AtBat         Hits        Walks         CRBI    DivisionW \n  91.5117981   -1.8685892    7.6043976    3.6976468    0.6430169 -122.9515338 \n     PutOuts \n   0.2643076 \n\n# A compact report\ndata.frame(term = names(final_coef), estimate = as.numeric(final_coef))\n\n         term     estimate\n1 (Intercept)   91.5117981\n2       AtBat   -1.8685892\n3        Hits    7.6043976\n4       Walks    3.6976468\n5        CRBI    0.6430169\n6   DivisionW -122.9515338\n7     PutOuts    0.2643076\n\n\n\n\n\n\n\n\nTip\n\n\n\nReporting tip: Always state (i) the criterion used (e.g., BIC), (ii) the model size, and (iii) the selected variables with their coefficients. Avoid training RÂ² aloneâ€”prefer Cp/BIC/Adjusted RÂ².\n\n\n\n\n\nâœ… What you should now be able to do\n\nPrepare data and run best subset and stepwise selection.\nUse Adjusted RÂ², Cp, and BIC to choose model size.\nExtract and communicate the chosen variables and coefficients.\n\n\nNext session weâ€™ll compare these selections using a validation set and crossâ€‘validation, and then move to ridge and lasso.",
    "crumbs": [
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Supervision 3</span>"
    ]
  },
  {
    "objectID": "supervision_4.html",
    "href": "supervision_4.html",
    "title": "Supervision 4",
    "section": "",
    "text": "Lab 1 â€” Collinearity\nCollinearity (multicollinearity) among regressors occurs when two or more move closely together or have limited variability. It inflates the variance of estimated parameters (less precise (t)-tests), even though OLS estimates remain unbiased. As a result, a model may have a high (R^2) or a large Fâ€‘statistic but insignificant individual coefficients.",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Supervision 4</span>"
    ]
  },
  {
    "objectID": "supervision_4.html#lab-1-collinearity",
    "href": "supervision_4.html#lab-1-collinearity",
    "title": "Supervision 4",
    "section": "",
    "text": "ğŸ§° Packages\nPoEdata, broom, knitr, car\n\n# install.packages(c(\"PoEdata\",\"broom\",\"knitr\",\"car\"))  # if needed\nlibrary(PoEdata); library(broom); library(knitr); library(car)\n\nWarning: package 'broom' was built under R version 4.4.3\n\n\nWarning: package 'knitr' was built under R version 4.4.3\n\n\nLoading required package: carData\n\n# Example data: cars (mpg = miles per gallon; cyl = cylinders; eng = engine displacement; wgt = weight)\ndata(\"cars\", package = \"PoEdata\")\n\n# Simple model\nmod1 &lt;- lm(mpg ~ cyl, data = cars)\nkable(tidy(mod1), caption = \"A simple linear 'mpg' model\")\n\n\nA simple linear â€˜mpgâ€™ model\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n42.915505\n0.8348668\n51.40401\n0\n\n\ncyl\n-3.558078\n0.1456755\n-24.42468\n0\n\n\n\n\n\nNow add more regressors:\n\nmod2 &lt;- lm(mpg ~ cyl + eng + wgt, data = cars)\nkable(tidy(mod2), caption = \"Multivariate 'mpg' model\")\n\n\nMultivariate â€˜mpgâ€™ model\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n44.3709616\n1.4806851\n29.9665086\n0.0000000\n\n\ncyl\n-0.2677968\n0.4130673\n-0.6483126\n0.5171663\n\n\neng\n-0.0126740\n0.0082501\n-1.5362247\n0.1252983\n\n\nwgt\n-0.0057079\n0.0007139\n-7.9951428\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen adding eng and wgt, the coefficient for cyl can turn insignificantâ€”a classic sign of collinearity because these vehicle traits tend to move together.\n\n\n\n\nVariance Inflation Factor (VIF)\nThe VIF for regressor (x_k) is (_k = ), where (R_k^2) is from regressing (x_k) on the other regressors.\n\nv &lt;- car::vif(mod2)\ntab &lt;- data.frame(regressor = names(v), VIF = as.numeric(v), row.names = NULL)\nkable(tab, caption = \"Variance inflation factors for the 'mpg' regression model\")\n\n\nVariance inflation factors for the â€˜mpgâ€™ regression model\n\n\nregressor\nVIF\n\n\n\n\ncyl\n10.515508\n\n\neng\n15.786455\n\n\nwgt\n7.788716\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nRules of thumb\n- VIF &gt; 10 â†’ strong collinearity (commonly used cutoff)\n- VIF &gt; 5 â†’ moderate collinearity (early warning)\n\n\n\n\nMitigations (when VIFs are high)\n\nRemove or combine collinear variables (e.g., combine cyl and eng into a power index).\n\nUse PCA to produce orthogonal components.\n\nStandardise/centre variables (helps especially with interactions/polynomials).\n\nUse Ridge regression if retaining all variables is preferred.\n\nConsider transformations (e.g., logs).",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Supervision 4</span>"
    ]
  },
  {
    "objectID": "supervision_4.html#lab-2-heteroskedasticity",
    "href": "supervision_4.html#lab-2-heteroskedasticity",
    "title": "Supervision 4",
    "section": "Lab 2 â€” Heteroskedasticity",
    "text": "Lab 2 â€” Heteroskedasticity\nThe Gaussâ€“Markov theorem assumes homoskedasticity (constant error variance (^2)). In many economic datasets, variance grows with some regressors (e.g., higherâ€‘income households show more dispersion in expenditure). With heteroskedasticity, OLS coefficients remain unbiased, but standard errors and therefore inference are wrong unless corrected.\n\nğŸ§° Packages\nlmtest, broom, PoEdata, car, sandwich, knitr\n\n# install.packages(c(\"lmtest\",\"broom\",\"PoEdata\",\"car\",\"sandwich\",\"knitr\"))  # if needed\nlibrary(lmtest); library(broom); library(PoEdata); library(car); library(sandwich); library(knitr)\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\ndata(\"food\", package=\"PoEdata\")\nmod1 &lt;- lm(food_exp ~ income, data = food)\n\n# Scatter and fitted line\nplot(food$income, food$food_exp, xlab=\"income\", ylab=\"food expenditure\", pch=19, col=\"grey\")\nabline(mod1, lwd=2)\n\n\n\n\n\n\n\n\n\n\nSpotting heteroskedasticity with residual plots\n\nres &lt;- residuals(mod1); yhat &lt;- fitted(mod1)\nplot(food$income, res, xlab=\"income\", ylab=\"residuals\", pch=19, col=\"grey\")\nabline(h=0, lty=2)\n\n\n\n\n\n\n\nplot(yhat, res, xlab=\"fitted values\", ylab=\"residuals\", pch=19, col=\"grey\")\nabline(h=0, lty=2)\n\n\n\n\n\n\n\n\n\n\nBreuschâ€“Pagan test (manual construction)\n\nalpha &lt;- 0.05\nressq &lt;- resid(mod1)^2\nmodres &lt;- lm(ressq ~ income, data = food)       # auxiliary regression\nN &lt;- nobs(modres)\nS &lt;- summary(modres)$df[2]                       # df for regression (k)\nchisqcr &lt;- qchisq(1 - alpha, S)                  # critical value (right-tail)\nRsqres &lt;- summary(modres)$r.squared\nchisq &lt;- N * Rsqres\npval &lt;- 1 - pchisq(chisq, S)\nc(statistic = chisq, crit = chisqcr, p.value = pval)\n\nstatistic      crit   p.value \n 7.384424 53.383541  1.000000 \n\n\n\n\nWhite (quadratic) version\n\nmodres2 &lt;- lm(ressq ~ income + I(income^2), data = food)\nRsq2 &lt;- summary(modres2)$r.squared\nS2 &lt;- summary(modres2)$df[2]\nchisq2 &lt;- N * Rsq2\npval2 &lt;- 1 - pchisq(chisq2, S2)\nc(statistic = chisq2, df = S2, p.value = pval2)\n\nstatistic        df   p.value \n 7.555079 37.000000  1.000000 \n\n\n\n\nBreuschâ€“Pagan with bptest()\n\nkable(tidy(bptest(mod1)), caption = \"Breuschâ€“Pagan heteroskedasticity test\")\n\n\nBreuschâ€“Pagan heteroskedasticity test\n\n\nstatistic\np.value\nparameter\nmethod\n\n\n\n\n7.384424\n0.0065791\n1\nstudentized Breusch-Pagan test\n\n\n\n\n\n\n\nGoldfeldâ€“Quandt test (indicator split: metro vs rural)\n\nalpha &lt;- 0.05\ndata(\"cps2\", package=\"PoEdata\")\nm &lt;- cps2[cps2$metro==1, ]\nr &lt;- cps2[cps2$metro==0, ]\n\nwg1 &lt;- lm(wage ~ educ + exper, data = m)\nwg0 &lt;- lm(wage ~ educ + exper, data = r)\n\ndf1 &lt;- wg1$df.residual; df0 &lt;- wg0$df.residual\nsig1 &lt;- summary(wg1)$sigma^2; sig0 &lt;- summary(wg0)$sigma^2\nfstat &lt;- sig1/sig0\nFlc &lt;- qf(alpha/2, df1, df0); Fuc &lt;- qf(1-alpha/2, df1, df0)\nc(F = fstat, Flc = Flc, Fuc = Fuc)\n\n        F       Flc       Fuc \n2.0877623 0.8051984 1.2617297 \n\n\nGoldfeldâ€“Quandt without an indicator (split by median income):\n\nalpha &lt;- 0.05\nmedianincome &lt;- median(food$income)\nli &lt;- food[food$income &lt;= medianincome, ]\nhi &lt;- food[food$income &gt;= medianincome, ]\n\neqli &lt;- lm(food_exp ~ income, data = li)\neqhi &lt;- lm(food_exp ~ income, data = hi)\n\ndfli &lt;- eqli$df.residual; dfhi &lt;- eqhi$df.residual\nsqli &lt;- summary(eqli)$sigma^2; sqhi &lt;- summary(eqhi)$sigma^2\n\nfstat &lt;- sqhi/sqli\nFc &lt;- qf(1 - alpha, dfhi, dfli)\npval &lt;- 1 - pf(fstat, dfhi, dfli)\nc(F = fstat, Fcrit = Fc, p.value = pval)\n\n         F      Fcrit    p.value \n3.61475572 2.21719713 0.00459643 \n\n\nOr use gqtest() directly:\n\nfoodeq &lt;- lm(food_exp ~ income, data = food)\ntst &lt;- lmtest::gqtest(foodeq, point = 0.5, alternative = \"greater\", order.by = food$income)\nkable(tidy(tst), caption = \"R function `gqtest()` with the 'food' equation\")\n\nMultiple parameters; naming those columns df1 and df2.\n\n\n\nR function gqtest() with the â€˜foodâ€™ equation\n\n\n\n\n\n\n\n\n\n\ndf1\ndf2\nstatistic\np.value\nmethod\nalternative\n\n\n\n\n18\n18\n3.614756\n0.0045964\nGoldfeld-Quandt test\nvariance increases from segment 1 to 2\n\n\n\n\n\n\n\nHeteroskedasticityâ€‘consistent (HC) standard errors\n\nfoodeq &lt;- lm(food_exp ~ income, data = food)\nkable(tidy(foodeq), caption = \"Regular standard errors in the 'food' equation\")\n\n\nRegular standard errors in the â€˜foodâ€™ equation\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n83.41600\n43.410163\n1.921578\n0.0621824\n\n\nincome\n10.20964\n2.093263\n4.877381\n0.0000195\n\n\n\n\ncov1 &lt;- car::hccm(foodeq, type = \"hc1\")\nfood.HC1 &lt;- lmtest::coeftest(foodeq, vcov. = cov1)\nkable(tidy(food.HC1), caption = \"Robust (HC1) standard errors in the 'food' equation\")\n\n\nRobust (HC1) standard errors in the â€˜foodâ€™ equation\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n83.41600\n27.463748\n3.037313\n0.0042989\n\n\nincome\n10.20964\n1.809077\n5.643566\n0.0000018\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nRobust (HC) errors fix inference under heteroskedasticity, but the point estimates are unchanged.",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Supervision 4</span>"
    ]
  },
  {
    "objectID": "supervision_4.html#lab-3-serial-correlation-autocorrelation",
    "href": "supervision_4.html#lab-3-serial-correlation-autocorrelation",
    "title": "Supervision 4",
    "section": "Lab 3 â€” Serial Correlation (Autocorrelation)",
    "text": "Lab 3 â€” Serial Correlation (Autocorrelation)\nSerial correlation is correlation across time in a series. In regression, autocorrelated errors lead to incorrect standard errors (and misleading (t)-tests).\n\nExample: growth vs unemployment (Okunâ€™s data)\n\ndata(\"okun\", package=\"PoEdata\")\nokun.ts &lt;- ts(okun, start=c(1948,1), frequency=4)\n\nplot(okun.ts[,\"g\"], ylab=\"growth\")\n\n\n\n\n\n\n\nplot(okun.ts[,\"u\"], ylab=\"unemployment\")\n\n\n\n\n\n\n\n# Scatter with lags\nggL1 &lt;- data.frame(g = okun.ts[,\"g\"], gL1 = stats::lag(okun.ts[,\"g\"], -1))\nplot(ggL1); abline(h=mean(ggL1$gL1, na.rm=TRUE), v=mean(ggL1$g, na.rm=TRUE), lty=2)\n\n\n\n\n\n\n\nggL2 &lt;- data.frame(g = okun.ts[,\"g\"], gL2 = stats::lag(okun.ts[,\"g\"], -2))\nplot(ggL2); abline(h=mean(ggL2$gL2, na.rm=TRUE), v=mean(ggL2$g, na.rm=TRUE), lty=2)\n\n\n\n\n\n\n\n# Correlogram\nacf(okun.ts[,\"g\"])\n\n\n\n\n\n\n\n\n\n\nPhillips curve example and BG/DW tests\n\nlibrary(dynlm)\n\nWarning: package 'dynlm' was built under R version 4.4.3\n\ndata(\"phillips_aus\", package=\"PoEdata\")\nphill.ts &lt;- ts(phillips_aus, start=c(1987,1), end=c(2009,3), frequency=4)\ninflation &lt;- phill.ts[,\"inf\"]\nDu &lt;- diff(phill.ts[,\"u\"])\n\n# FDL model: inf_t = beta1 + beta2 * diff(u_t) + e_t\nphill.dyn &lt;- dynlm(inf ~ diff(u), data = phill.ts)\nkable(tidy(phill.dyn), caption=\"Summary of the `phillips` model\")\n\nWarning: The `tidy()` method for objects of class `dynlm` is not maintained by the broom team, and is only supported through the `lm` tidier method. Please be cautious in interpreting and reporting broom output.\n\nThis warning is displayed once per session.\n\n\n\nSummary of the phillips model\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.7776213\n0.0658249\n11.813474\n0.0000000\n\n\ndiff(u)\n-0.5278638\n0.2294049\n-2.301014\n0.0237539\n\n\n\n\n# Residual plot and correlogram\nehat &lt;- resid(phill.dyn)\nplot(ehat); abline(h=0, lty=2)\n\n\n\n\n\n\n\nacf(ehat)\n\n\n\n\n\n\n\n\nBreuschâ€“Godfrey tests (different orders/statistics):\n\n# NOTE: preserving your object names a, b, c, d and test types.\n# (We only use base::c() below to avoid masking by object 'c')\na &lt;- lmtest::bgtest(phill.dyn, order=1, type=\"F\",    fill=0)\nb &lt;- lmtest::bgtest(phill.dyn, order=1, type=\"F\",    fill=NA)\nc &lt;- lmtest::bgtest(phill.dyn, order=4, type=\"Chisq\",fill=0)\nd &lt;- lmtest::bgtest(phill.dyn, order=4, type=\"Chisq\",fill=NA)\n\ndfr &lt;- data.frame(\n  Method    = base::c(\"1, F, 0\",\"1, F, NA\",\"4, Chisq, 0\",\"4, Chisq, NA\"),\n  Statistic = base::c(unname(a$statistic), unname(b$statistic), unname(c$statistic), unname(d$statistic)),\n  Parameters= base::c(sprintf(\"df1=%g, df2=%g\", a$parameter[1], a$parameter[2]),\n                      sprintf(\"df1=%g, df2=%g\", b$parameter[1], b$parameter[2]),\n                      sprintf(\"df=%g\",          c$parameter),\n                      sprintf(\"df=%g\",          d$parameter)),\n  p_value   = base::c(a$p.value, b$p.value, c$p.value, d$p.value)\n)\nknitr::kable(dfr, caption=\"Breuschâ€“Godfrey test for the Phillips example\")\n\n\nBreuschâ€“Godfrey test for the Phillips example\n\n\nMethod\nStatistic\nParameters\np_value\n\n\n\n\n1, F, 0\n38.46538\ndf1=1, df2=87\n0e+00\n\n\n1, F, NA\n38.69456\ndf1=1, df2=86\n0e+00\n\n\n4, Chisq, 0\n36.67190\ndf=4\n2e-07\n\n\n4, Chisq, NA\n33.59372\ndf=4\n9e-07\n\n\n\n\n\nDurbinâ€“Watson (legacy but useful for small samples):\n\nlmtest::dwtest(phill.dyn)\n\n\n    Durbin-Watson test\n\ndata:  phill.dyn\nDW = 0.88729, p-value = 2.198e-09\nalternative hypothesis: true autocorrelation is greater than 0",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Supervision 4</span>"
    ]
  },
  {
    "objectID": "supervision_4.html#lab-4-hac-neweywest-standard-errors",
    "href": "supervision_4.html#lab-4-hac-neweywest-standard-errors",
    "title": "Supervision 4",
    "section": "Lab 4 â€” HAC (Neweyâ€“West) Standard Errors",
    "text": "Lab 4 â€” HAC (Neweyâ€“West) Standard Errors\nCorrect standard errors under autocorrelation (and heteroskedasticity) using HAC estimators.\n\nlibrary(sandwich); library(lmtest)\n\ns0 &lt;- coeftest(phill.dyn)                              # incorrect under AC\ns1 &lt;- coeftest(phill.dyn, vcov.=vcovHAC(phill.dyn))    # HAC\ns2 &lt;- coeftest(phill.dyn, vcov.=NeweyWest(phill.dyn))  # Neweyâ€“West\ns3 &lt;- coeftest(phill.dyn, vcov.=kernHAC(phill.dyn))    # kernel HAC\n\ntbl &lt;- data.frame(cbind(s0[c(3,4)], s1[c(3,4)], s2[c(3,4)], s3[c(3,4)]))\nnames(tbl) &lt;- c(\"Incorrect\",\"vcovHAC\",\"NeweyWest\",\"kernHAC\")\nrow.names(tbl) &lt;- c(\"(Intercept)\",\"Du\")\nkable(tbl, digits=3, caption=\"Comparing standard errors for the Phillips model\")\n\n\nComparing standard errors for the Phillips model\n\n\n\nIncorrect\nvcovHAC\nNeweyWest\nkernHAC\n\n\n\n\n(Intercept)\n0.066\n0.095\n0.128\n0.131\n\n\nDu\n0.229\n0.304\n0.331\n0.335\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nHAC fixes inference but not efficiency: OLS with HAC is still not minimumâ€‘variance when errors are autocorrelated.",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Supervision 4</span>"
    ]
  },
  {
    "objectID": "supervision_4.html#lab-5-ar1-error-structure-diagnostics",
    "href": "supervision_4.html#lab-5-ar1-error-structure-diagnostics",
    "title": "Supervision 4",
    "section": "Lab 5 â€” AR(1) Error Structure (Diagnostics)",
    "text": "Lab 5 â€” AR(1) Error Structure (Diagnostics)\nAssume errors follow an AR(1) process (e_t = e_{t-1} + _t), with (||&lt;1). A quick diagnostic is to inspect the first few autocorrelations of residuals.\n\nehat &lt;- resid(phill.dyn)\nac &lt;- acf(ehat, plot = FALSE)\nac$acf[2:6]   # autocorrelations at lags 1..5\n\n[1] 0.5486586 0.4557325 0.4332158 0.4204936 0.3390342\n\n\nThe firstâ€‘lag correlation is a simple estimate of () ((= r_1)). If large and significant, consider modelling errors explicitly (e.g., GLS/AR models) or using HAC for valid inference when staying with OLS.",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Supervision 4</span>"
    ]
  }
]