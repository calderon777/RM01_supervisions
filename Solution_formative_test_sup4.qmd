---
title: "Solution to in‑class Sup 4"
author: "Camilo Calderon-Morales, PhD"
date: 2025-10-27
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: show
execute:
  echo: true
  warning: false
  message: false
---

## Overview

This document reproduces the analysis with **concise `#` comments inside each R chunk** so students see *why* each step is taken.

**Work flow:** run baseline model 1 \> VIF test \> fix model if high multicolinearity \> Test autocorrelation from previous step \> fix the model if high autocorrelation \> Test for heteroskedasticity \> fix the model if high heteroskedasticity.

---

## 0) Packages

```{r}
# Minimal package set for this workflow
pkgs <- c("PoEdata","car","lmtest","sandwich","dplyr","zoo")

# Install any missing packages (safe check)
to_install <- pkgs[!sapply(pkgs, requireNamespace, quietly = TRUE)]
if (length(to_install)) install.packages(to_install, repos = "https://cloud.r-project.org")

# Load libraries
library(PoEdata)     # provides 'rice' dataset
library(car)         # VIF for multicollinearity
library(lmtest)      # dwtest, bgtest, bptest
library(sandwich)    # robust variance estimators (HC)
library(dplyr)       # arrange, mutate, lag
```

## 1) Data

```{r}
# Load and time-order the data
data(rice)                                  # bring 'rice' into the workspace
rice <- rice[order(rice$year), ]            # ensure time order for lags and DW/BG tests

# Baseline production function
form <- prod ~ area + fert + labor + firm   # 'firm' is an identifier; expect little role
```

## 2) Baseline OLS

```{r}
# Estimate baseline OLS
m <- lm(form, data = rice)

# Inspect fit and signs/magnitudes
cat("\n=== OLS summary ===\n"); print(summary(m))
```

## 3) Multicollinearity (VIF)

```{r}
# Diagnose collinearity: rule of thumb VIF > 5 (moderate), > 10 (high)
cat("\n=== Multicollinearity (VIF) ===\n"); print(vif(m))
```

## 4) Reduce collinearity via transformation

```{r}
# Construct labor per area to reduce collinearity between labor and area
rice$labor_density <- rice$labor / rice$area   # density transformation

# Refit a more parsimonious model (drop 'firm' id)
m2 <- lm(prod ~ area + fert + labor_density, data = rice)

# Check VIFs fall meaningfully
cat("\n=== VIF after transformation (m2) ===\n"); print(vif(m2))

# Compare fit (R^2) and significance with baseline
cat("\n=== OLS summary (m2) ===\n"); print(summary(m2))
```

Answer (VIF): Using a VIF threshold of 5 (NOte 5–10 considered moderate, >10 high), the baseline model reports VIFs of area = 7.27, fert = 3.74, and labor = 7.06, indicating moderate multicollinearity for area and labor. The source is conceptual overlap between cultivated area and the scale of labor. Remedy: I replace labor with labor_density = labor/area to orthogonalise scale and intensity. In the revised model, VIFs fall to area = 3.74, fert = 3.61, labor_density = 1.10, which are comfortably below the threshold.

## 4a) Autocorrelation diagnostics

```{r}
# Durbin–Watson (focus on AR(1) positive autocorrelation under default alt)
cat("\n=== Autocorrelation on m2 ===\n")
cat("Durbin–Watson:\n"); print(dwtest(m2))

# Breusch–Godfrey (general serial correlation; here AR(1) for comparability)
cat("\nBreusch–Godfrey (AR1):\n"); print(bgtest(m2, order = 1))

# Note: p < 0.05 indicates evidence of autocorrelation
```

Answer (autocorrelation): The initial diagnostics on the revised level model show positive serial correlation: DW ≈ 1.74 (p ≈ 0.006) and BG(1) p ≈ 0.013. The ACF/PACF of residuals suggest an AR(1) pattern with some evidence consistent with possible AR(2) dynamics. I therefore consider dynamic specifications and a log–log transformation (which often stabilises variance and improves dynamics).

### Create lag and plot correlograms

```{r}
# Create lag of dependent variable for dynamic model
rice <- rice |>
  arrange(year) |>
  mutate(prod_lag = dplyr::lag(prod))   # first observation becomes NA by construction

# ACF/PACF of residuals (visual check)
acf(m2$residuals, main = "ACF of OLS residuals (m2)")    # spikes suggest serial correlation
pacf(m2$residuals, main = "PACF of OLS residuals (m2)")

# Align sample by dropping rows with NA lag
rice_lag <- na.omit(rice)               # keep complete cases for dynamic models
```

## 4b) Dynamic model and log–log refinement

```{r}
# Dynamic level model: include the lagged dependent variable
m3 <- lm(prod ~ prod_lag + area + fert + labor_density, data = rice_lag)
cat("\n=== Dynamic model in levels (m3) ===\n"); print(summary(m3))
cat("\nDW on m3:\n"); print(dwtest(m3))
cat("\nBG(AR1) on m3:\n"); print(bgtest(m3, order = 1))

# Log–log specification: interpretable elasticities, often stabilizes variance
best <- lm(log(prod) ~ log(prod_lag) + log(area) + log(fert) + log(labor_density),
           data = rice_lag)

# Multicollinearity check in final model
cat("\n=== VIF (final log–log model) ===\n"); print(vif(best))

# Final model summary: coefficients are elasticities
cat("\n=== Final model (log–log) summary ===\n"); print(summary(best))

# Autocorrelation checks on final model (expect no serial correlation)
cat("\nDW on final model:\n"); print(dwtest(best))
cat("\nBG(AR1) on final model:\n"); print(bgtest(best, order = 1))
```

Answer (autocorrelation – final model): In the preferred log–log model with log(prod_lag), both tests indicate no residual serial correlation: DW ≈ 2.02 (p ≈ 0.55) and BG(1) p ≈ 0.83. This, together with acceptable VIFs (≤~4.7), supports using the log–log model for inference and interpretation as elasticities.

## 5) Heteroskedasticity tests

```{r}
# Breusch–Pagan: H0 = homoskedasticity
cat("\n=== Heteroskedasticity ===\n")
cat("Breusch–Pagan:\n"); print(bptest(best))

# White-type (auxiliary regression on fitted and fitted^2)
cat("\nWhite-type (fitted & fitted^2):\n")
print(bptest(best, ~ fitted(best) + I(fitted(best)^2), data = rice_lag))
```

## 6) Robust inference (HC1)

```{r}
# Use heteroskedasticity-consistent (HC1) standard errors for inference
# HAC is not needed because DW/BG suggest no serial correlation in the final model.
cat("\n=== Coefficients with robust (HC1) SE ===\n")
print(lmtest::coeftest(best, vcov = sandwich::vcovHC(best, type = "HC1")))

cat("\n=== Coefficients with HAC (Newey–West, lag = 1) ===\n")
print(lmtest::coeftest(best, vcov. = sandwich::NeweyWest(best, lag = 1, prewhite = FALSE)))
```

Answer (heteroskedasticity & inference): Both BP and White-type tests reject homoskedasticity, so I report HC1 and also HAC (Newey–West) inference. Comparing p‑values across classical vs HC1 vs HAC, the significance pattern is robust: at the 5% level, log(area), log(fert), and log(labor_density) remain significant; log(prod_lag) also remains significant at ≈5% (small negative carryover). Hence, substantive conclusions are unchanged by robust/HAC corrections.

## Short interpretation notes (for students)

-   **Collinearity:** Replacing `labor` with `labor_density` reduced VIFs (improves stability of estimates).
-   **Autocorrelation:** Final log–log model (`best`) passes DW/BG (no serial correlation).
-   **Heteroskedasticity:** BP/White indicate non-constant variance → report **robust SEs**.
-   **Elasticities:** In the log–log model, coefficients read as % changes (e.g., 0.82 on `log(area)` ≈ 1% ↑ area → 0.82% ↑ output, ceteris paribus).

Final report: The preferred specification is a log–log production function with a dynamic term: $log(\text{prod}_t) = \alpha + \beta1 \log(\text{prod}{t-1}) + \beta_2 \log(\text{area}_t) + \beta_3 \log(\text{fert}_t) +$ $\beta_4 \log(\text{labor/area}t) + u_t$ 

Diagnostics follow textbook order. Multicollinearity: baseline VIFs were moderate (area ≈ 7.27, labor ≈ 7.06), so I replaced labor with labor density, reducing VIFs to ≤~3.74. Autocorrelation: the revised level model exhibited positive AR(1) serial correlation (DW ≈ 1.74; BG p ≈ 0.013; ACF consistent with AR(1) and possible AR(2)), which motivated adding a lagged dependent variable and moving to a log–log form. In the final model, DW ≈ 2.02 and BG(1) p ≈ 0.83 indicate no remaining autocorrelation. Heteroskedasticity: both BP and White-type tests reject homoskedasticity, so I report HC1 and HAC (Newey–West) standard errors; inference is unchanged. Interpretation: Coefficients are elasticities. Output elasticity w.r.t. cultivated area is ≈0.82, fertiliser ≈0.20, and labor density ≈0.44: a 1% rise in each raises output by roughly 0.82%, 0.20%, and 0.44%, respectively. The small negative coefficient on ($\log(\text{prod}{t-1}$)) suggests modest mean reversion after shocks. Overall, the transformed specification is well‑behaved and economically interpretable, with robust inference to heteroskedasticity and HAC corrections.